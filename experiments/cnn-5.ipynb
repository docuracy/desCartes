{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/docuracy/desCartes/blob/main/experiments/cnn-5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pagxqe-djTb-"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate GCS, mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!gcloud auth application-default login\n",
        "!gcloud config set project descartes-404713"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMuhev-dZtw_",
        "outputId": "459aeb15-d637-4c4b-b3ed-f69ff684bb8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow)\n",
            "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 0.4.6\n",
            "    Uninstalling google-auth-oauthlib-0.4.6:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.0\n",
            "    Uninstalling tensorboard-2.12.0:\n",
            "      Successfully uninstalled tensorboard-2.12.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed google-auth-oauthlib-1.2.0 keras-2.15.0 tensorboard-2.15.1 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0\n"
          ]
        }
      ],
      "source": [
        "#@title Upgrade TensorFlow\n",
        "\n",
        "!pip install --upgrade tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQNXRHBq9-NY"
      },
      "outputs": [],
      "source": [
        "#@title Initialise directories and global variables\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Directory containing scripts such as 'map_from_tiles'\n",
        "scripts_directory = '/content/drive/MyDrive/Colab Notebooks/scripts'\n",
        "sys.path.append(scripts_directory)\n",
        "\n",
        "# Directories used by 'map_from_tiles'\n",
        "temp_directory = f\"{scripts_directory}/temp\"\n",
        "cache_directory = f\"{scripts_directory}/data/cache\"\n",
        "\n",
        "training_data_directory = '/content/drive/MyDrive/desCartes/training_data/'\n",
        "map_directory = f\"{training_data_directory}maps/\"\n",
        "map_classified_s1_directory = f\"{map_directory}classified_s1/\"\n",
        "map_one_inch_directory = f\"{map_directory}one_inch/\"\n",
        "map_osm_directory = f\"{map_directory}osm/\"\n",
        "map_dem_directory = f\"{map_directory}dem/\"\n",
        "map_elevation_directory = f\"{map_dem_directory}elevation/\"\n",
        "map_slope_directory = f\"{map_dem_directory}slope/\"\n",
        "map_augmented_s1_directory = f\"{map_directory}augmented_s1/\"\n",
        "map_binary_directory = f\"{map_directory}binary/\"\n",
        "map_skeleton_directory = f\"{map_directory}skeleton/\"\n",
        "map_output_directory = f\"{map_directory}output/\"\n",
        "map_mask_directory = f\"{map_output_directory}masks/\"\n",
        "map_overlay_directory = f\"{map_output_directory}overlays/\"\n",
        "map_geotiff_directory = f\"{map_output_directory}geotiffs/\"\n",
        "labels_directory = f\"{map_directory}labels/\"\n",
        "labels_raster_directory = f\"{labels_directory}raster/\"\n",
        "labels_overlay_directory = f\"{labels_directory}overlay/\"\n",
        "\n",
        "tile_directory = '/content/tiles/'\n",
        "tile_size = 256 # (px)\n",
        "min_overlap = 16 # Minimum tile overlap (px)\n",
        "\n",
        "# GeoPackage containing map annotations created in QGIS\n",
        "geopackage_path = '/content/drive/MyDrive/desCartes/templates/labels.gpkg'\n",
        "linestring_buffer = 3 # (px) Use False for no buffer\n",
        "\n",
        "maptiler_key = 'U2vLM8EbXurAd3Gq6C45'\n",
        "\n",
        "# UK Great Britain, Ordnance Survey six-inch to the mile (1:10,560), 1888-1913 https://cloud.maptiler.com/tiles/uk-osgb10k1888/\n",
        "basemap_url = 'https://api.maptiler.com/tiles/uk-osgb10k1888/{z}/{x}/{y}.jpg' + f'?key={maptiler_key}'\n",
        "\n",
        "# UK Great Britain, Ordnance Survey one-inch to the mile (1:63,360), 1888-1913 https://cloud.maptiler.com/tiles/uk-osgb63k1885/\n",
        "basemap_url_one_inch = 'https://api.maptiler.com/tiles/uk-osgb63k1885/{z}/{x}/{y}.png' + f'?key={maptiler_key}'\n",
        "\n",
        "# DEM Tiles - see https://documentation.maptiler.com/hc/en-us/articles/4405444055313-RGB-Terrain-by-MapTiler\n",
        "dem_tilesource = 'https://api.maptiler.com/tiles/terrain-rgb-v2/{z}/{x}/{y}.webp' + f'?key={maptiler_key}'\n",
        "dem_max_zoom = 14\n",
        "\n",
        "# Ilastik model used for Stage 1 pixel classification\n",
        "ilastik_project_file = \"/content/drive/MyDrive/desCartes/ilastik/preprocess.ilp\"\n",
        "ilastik_executable = './ilastik-1.4.0-Linux/run_ilastik.sh'\n",
        "\n",
        "# Directory for saving trained CNN models\n",
        "model_directory = \"/content/drive/MyDrive/desCartes/models\"\n",
        "\n",
        "label_strings_file = os.path.join(model_directory, 'label_strings.txt')\n",
        "class_weights_file = os.path.join(model_directory, 'class_weights.json')\n",
        "num_classes = 5 # Allows for fill (zero) and road classes 1 to 4 (determined by QGIS labelling)\n",
        "\n",
        "# Google Cloud Services\n",
        "gcs_key_path = '/content/drive/MyDrive/desCartes/descartes-404713-cccf7c3921aa.json'\n",
        "gcs_project_id = 'descartes-404713'\n",
        "gcs_bucket_name = 'descartes'\n",
        "gcs_data_directory = \"training_data\"\n",
        "\n",
        "# Set the split ratios and batch size for training data\n",
        "TFRecord_batch_size = 16\n",
        "train_ratio = 0.85\n",
        "eval_ratio = 0.15\n",
        "\n",
        "initial_learning_rate = 0.0001\n",
        "\n",
        "# Inference: Color mappings for classes\n",
        "class_colors = {\n",
        "    0: (0, 0, 0, 0),  # Transparent (background)\n",
        "    1: (178,24,43,180),  # Red\n",
        "    2: (239,138,98,180),  # Orange\n",
        "    3: (84,39,136,180),  # Purple\n",
        "    4: (153,142,195,180),  # Lilac\n",
        "}\n",
        "\n",
        "# Create directories if they do not exist\n",
        "directories_to_create = [\n",
        "    temp_directory,\n",
        "    cache_directory,\n",
        "    training_data_directory,\n",
        "    map_directory,\n",
        "    map_one_inch_directory,\n",
        "    map_osm_directory,\n",
        "    map_dem_directory,\n",
        "    map_elevation_directory,\n",
        "    map_slope_directory,\n",
        "    map_classified_s1_directory,\n",
        "    map_augmented_s1_directory,\n",
        "    map_binary_directory,\n",
        "    map_skeleton_directory,\n",
        "    map_output_directory,\n",
        "    map_mask_directory,\n",
        "    map_overlay_directory,\n",
        "    map_geotiff_directory,\n",
        "    labels_directory,\n",
        "    labels_raster_directory,\n",
        "    labels_overlay_directory,\n",
        "    model_directory,\n",
        "]\n",
        "\n",
        "for directory in directories_to_create:\n",
        "    os.makedirs(directory, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R2Es76BI8qf"
      },
      "source": [
        "# Load and Train CNN Model: **must be run on TPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKcKPgINca2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "cellView": "form",
        "outputId": "8250b0cc-83d6-4d40-c796-6fbfef93cc90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.123.118.114:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        }
      ],
      "source": [
        "#@title Clear Session\n",
        "\n",
        "# Assuming `model` is the name of your compiled Keras model\n",
        "# Clear Keras session\n",
        "from keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR_KnZtH5nIV",
        "outputId": "05f73d7f-b06a-412b-d704-27f264b39a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.123.118.114:8470']\n",
            "TPU system already initialized.\n",
            "class_weights_list: {0: 0.20887414958955328, 1: 18.736409394308616, 2: 8.051957535094475, 3: 64.33833280169463, 4: 51.7601309518174}\n",
            "Training a new model.\n",
            "Encoder - size: 1024; filter: 3\n",
            "Encoder - size: 1024; filter: 3\n",
            "Encoder - size: 512; filter: 5\n",
            "Encoder - size: 256; filter: 5\n",
            "Encoder - size: 128; filter: 7\n",
            "Encoder - size: 64; filter: 9\n",
            "Decoder - size: 64; filter: 9; strides: (2, 2)\n",
            "Decoder - size: 128; filter: 7; strides: (2, 2)\n",
            "Decoder - size: 256; filter: 5; strides: (2, 2)\n",
            "Decoder - size: 512; filter: 5; strides: (2, 2)\n",
            "Decoder - size: 1024; filter: 3; strides: (2, 2)\n",
            "Decoder - size: 1024; filter: 3; strides: (2, 2)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 28)]       0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 256, 256, 1024)       259072    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 256, 256, 1024)       4096      ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 256, 256, 1024)       0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 1024)       9438208   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 256, 256, 1024)       4096      ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 1024)       0         ['batch_normalization_1[0][0]'\n",
            " D)                                                                 ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 1024)       9438208   ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 128, 128, 1024)       4096      ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 128, 128, 1024)       0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 1024)       9438208   ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 128, 128, 1024)       4096      ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 1024)         0         ['batch_normalization_3[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 512)          1310771   ['max_pooling2d_1[0][0]']     \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 64, 64, 512)          2048      ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 64, 64, 512)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 512)          6554112   ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 64, 64, 512)          2048      ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 512)          0         ['batch_normalization_5[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 256)          3277056   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 256)          1024      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 32, 32, 256)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 256)          1638656   ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 256)          1024      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 256)          0         ['batch_normalization_7[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 128)          1605760   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 128)          512       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 16, 16, 128)          0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 128)          802944    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 128)          512       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 128)            0         ['batch_normalization_9[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 64)             663616    ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 8, 8, 64)             256       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 8, 8, 64)             0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 64)             331840    ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 8, 8, 64)             256       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 64)             0         ['batch_normalization_11[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 4, 4, 128)            663680    ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 4, 4, 128)            0         ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 8, 8, 64)             663616    ['dropout_6[0][0]']           \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 8, 8, 128)            0         ['conv2d_transpose[0][0]',    \n",
            "                                                                     'batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 64)             663616    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 16, 16, 128)          401536    ['conv2d_13[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 16, 16, 256)          0         ['conv2d_transpose_1[0][0]',  \n",
            " )                                                                   'batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 128)          1605760   ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 32, 32, 256)          819456    ['conv2d_14[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 32, 32, 512)          0         ['conv2d_transpose_2[0][0]',  \n",
            " )                                                                   'batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 32, 32, 256)          3277056   ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 64, 64, 512)          3277312   ['conv2d_15[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 64, 64, 1024)         0         ['conv2d_transpose_3[0][0]',  \n",
            " )                                                                   'batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 64, 64, 512)          1310771   ['concatenate_3[0][0]']       \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 128, 128, 1024)       4719616   ['conv2d_16[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 128, 128, 2048)       0         ['conv2d_transpose_4[0][0]',  \n",
            " )                                                                   'batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 128, 128, 1024)       1887539   ['concatenate_4[0][0]']       \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 256, 256, 1024)       9438208   ['conv2d_17[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 256, 256, 2048)       0         ['conv2d_transpose_5[0][0]',  \n",
            " )                                                                   'batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 256, 256, 1024)       1887539   ['concatenate_5[0][0]']       \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 256, 256, 5)          46085     ['conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 256, 256, 5)          0         ['conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 133013893 (507.41 MB)\n",
            "Trainable params: 133001861 (507.36 MB)\n",
            "Non-trainable params: 12032 (47.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#@title v5 Load and Compile Model\n",
        "\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "import json\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.saving import load_model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import Sequence, custom_object_scope\n",
        "from tensorflow.keras.metrics import Metric, CategoricalAccuracy, MeanIoU\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import Loss, CategoricalCrossentropy, CategoricalFocalCrossentropy\n",
        "\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, MaxPooling2D, Conv2DTranspose, concatenate, Activation\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "reload_existing = False # @param {type:\"boolean\"}\n",
        "reduce_classes = False # @param {type:\"boolean\"}\n",
        "ignore_ilastik = False # @param {type:\"boolean\"}\n",
        "\n",
        "output_classes = 2 if reduce_classes else 5\n",
        "\n",
        "##############################################################################\n",
        "# Detect and initialize the TPU\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    print('Not connected to a TPU runtime. Running on CPU/GPU.')\n",
        "\n",
        "try:\n",
        "    # Check if TPU system has already been initialized\n",
        "    if not tf.config.list_logical_devices('TPU'):\n",
        "        tf.config.experimental_connect_to_cluster(tpu)\n",
        "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "        tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    else:\n",
        "        print('TPU system already initialized.')\n",
        "\n",
        "except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime.')\n",
        "##############################################################################\n",
        "\n",
        "label_strings = []\n",
        "with open(label_strings_file, 'r') as file:\n",
        "    for line in file:\n",
        "        label = line.strip()  # Remove leading/trailing whitespace, like newline characters\n",
        "        label_strings.append(label)\n",
        "\n",
        "def unet_model(\n",
        "    input_shape=(256, 256, 28),\n",
        "    num_classes=output_classes,\n",
        "    # sizes = [64, 128, 256, 512, 1024, 2048],\n",
        "    # filters = [3, 3, 3, 3, 3, 3],\n",
        "    # sizes = [256, 512, 512, 1024],\n",
        "    # filters = [3, 3, 5, 7],\n",
        "    # sizes = [512, 256, 128, 64],\n",
        "    # filters = [3, 3, 5, 7],\n",
        "    # sizes = [1024, 1024, 128, 64],\n",
        "    # filters = [3, 3, 5, 7],\n",
        "    # sizes = [1024, 1024, 128, 32, 8], # 20 mins per epoch; failed at 30\n",
        "    # filters = [3, 3, 5, 7, 9],\n",
        "    # sizes = [1024, 128, 8], # 20 mins per epoch, slow convergence to inadequate categorical crossentropy\n",
        "    # filters = [3, 5, 9],\n",
        "    # sizes = [1024, 1024, 64], # 18 mins per epoch\n",
        "    # filters = [3, 3, 7],\n",
        "    # sizes = [1024, 1024, 1024], # Crashed memory\n",
        "    # filters = [3, 3, 3],\n",
        "    # sizes = [1024, 1024, 128, 8], # 20 mins per epoch, 0.1350 @Epoch 30 (crashed)\n",
        "    # filters = [3, 3, 5, 9],\n",
        "    # sizes = [1024, 512, 256, 128],\n",
        "    # filters = [3, 3, 5, 5],\n",
        "    # sizes = [1024, 1024, 128, 32, 8], # 20 mins per epoch; failed at 30\n",
        "    # filters = [3, 3, 5, 7, 9],\n",
        "    # sizes = [512, 512, 256, 128, 64],\n",
        "    # filters = [3, 3, 5, 7, 9],\n",
        "    sizes = [1024, 1024, 512, 256, 128, 64],\n",
        "    filters = [3, 3, 5, 5, 7, 9],\n",
        "    ):\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    encoders_layers = []\n",
        "    for i, size in enumerate(sizes):\n",
        "\n",
        "        # Vary the regularization strength based on the encoder depth or other criteria\n",
        "        regularization_strength = 1e-5 if i < 2 else 1e-4\n",
        "\n",
        "        print(f\"Encoder - size: {size}; filter: {filters[i]}\")\n",
        "\n",
        "        x = Conv2D(size, (filters[i], filters[i]), activation=tf.nn.leaky_relu, padding='same', kernel_regularizer=l2(regularization_strength))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(size, (filters[i], filters[i]), activation=tf.nn.leaky_relu, padding='same', kernel_regularizer=l2(regularization_strength))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        encoder_pool = MaxPooling2D((2, 2))(x)\n",
        "        encoders_layers.append((x, encoder_pool))\n",
        "        x = encoder_pool\n",
        "\n",
        "    # Bottleneck\n",
        "    bottleneck_size = sizes[-1] * 2\n",
        "    x = Conv2D(bottleneck_size, (filters[-1], filters[-1]), activation=tf.nn.leaky_relu, padding='same', kernel_regularizer=l2(1e-5))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Decoder\n",
        "    for i, (encoder_layer, encoder_pool) in enumerate(reversed(encoders_layers)):\n",
        "        decoder_size = sizes[-i - 1]\n",
        "        stride_size = 2\n",
        "        strides = (stride_size, stride_size)\n",
        "\n",
        "        print(f\"Decoder - size: {decoder_size}; filter: {filters[-i-1]}; strides: {strides}\")\n",
        "\n",
        "        x = Conv2DTranspose(decoder_size, (filters[-i-1], filters[-i-1]), strides=strides, padding='same')(x)\n",
        "        x = concatenate([x, encoder_layer], axis=-1)\n",
        "        x = Conv2D(decoder_size, (filters[-i-1], filters[-i-1]), activation=tf.nn.leaky_relu, padding='same', kernel_regularizer=l2(1e-5))(x)\n",
        "\n",
        "    # Additional Convolutional Layer\n",
        "    x = Conv2D(num_classes, (filters[0], filters[0]), activation=tf.nn.leaky_relu, padding='same', kernel_regularizer=l2(1e-5))(x)\n",
        "\n",
        "    # Output\n",
        "    outputs = Activation('softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "def load_and_compile_model(resume, model_directory):\n",
        "    def load_class_weights(model_directory):\n",
        "        class_weights_file = os.path.join(model_directory, 'class_weights.json')\n",
        "        if os.path.exists(class_weights_file):\n",
        "            with open(class_weights_file, 'r') as json_file:\n",
        "                class_weights = json.load(json_file)\n",
        "                class_weights = {int(key): value for key, value in class_weights.items()}  # Convert keys to integers\n",
        "\n",
        "                # Convert class_weights to a list, matching the number of classes\n",
        "                num_classes = 5\n",
        "                class_weights_list = np.array([class_weights[i] for i in range(num_classes)], dtype=np.float32)\n",
        "                print(f\"class_weights_list: {class_weights}\")\n",
        "\n",
        "                if reduce_classes:\n",
        "                    adjusted_class_weights = np.zeros(2, dtype=np.float32)\n",
        "                    adjusted_class_weights[0] = 1 / (1 / class_weights_list[0] + 1 / class_weights_list[3] + 1 / class_weights_list[4])\n",
        "                    adjusted_class_weights[1] = 1 / (1 / class_weights_list[1] + 1 / class_weights_list[2])\n",
        "                    class_weights_list = adjusted_class_weights\n",
        "                    print(f\"Adjusted Class Weights: {class_weights_list}\")\n",
        "\n",
        "                return class_weights_list\n",
        "        else:\n",
        "            raise ValueError(\"Class weights not found. Cannot proceed without class weights.\")\n",
        "\n",
        "    class_weights_list = load_class_weights(model_directory)\n",
        "    model = None\n",
        "\n",
        "    with tpu_strategy.scope():\n",
        "\n",
        "        if resume:\n",
        "            # Load the most recent model (or its checkpoint) from the model_directory\n",
        "            model_files = sorted(glob.glob(os.path.join(model_directory, '*.keras')), key=os.path.getmtime)\n",
        "            print(model_files)\n",
        "            if model_files:\n",
        "                model_filepath = model_files[-1]\n",
        "                print(f\"Loading model: {model_filepath}\")\n",
        "                model = load_model(model_filepath)\n",
        "                print(f\"... loaded.\")\n",
        "            else:\n",
        "                print(\"No model to resume.\")\n",
        "\n",
        "        elif model is None:\n",
        "            # Create a new model\n",
        "            print(\"Training a new model.\")\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "            model_filepath = os.path.join(model_directory, f\"desCartes_{timestamp}.keras\")\n",
        "\n",
        "            model = unet_model()  # Use default inputs\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=Adam(learning_rate = initial_learning_rate),\n",
        "                loss=CategoricalFocalCrossentropy(alpha=class_weights_list),\n",
        "                metrics=['categorical_accuracy', 'categorical_crossentropy']\n",
        "            )\n",
        "\n",
        "        model.summary()\n",
        "        return model, model_filepath\n",
        "\n",
        "# Call load_and_compile_model to load or create and compile the model\n",
        "model, model_filepath = load_and_compile_model(resume=reload_existing, model_directory=model_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vraKwDVVKp8"
      },
      "outputs": [],
      "source": [
        "model_filepath = '/content/drive/MyDrive/desCartes/models/desCartes_20231207_0723.keras'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfNRfJLKapZi",
        "outputId": "a39e57c9-5da0-4102-fbd0-1856eb0ab87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/auth/_default.py:78: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
            "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "421 steps per epoch and 75 validation steps.\n",
            "Epoch 1/150\n",
            "421/421 [==============================] - 1575s 3s/step - loss: 0.6996 - categorical_accuracy: 0.7158 - categorical_crossentropy: 0.8235 - val_loss: 0.5216 - val_categorical_accuracy: 0.6706 - val_categorical_crossentropy: 0.8852 - lr: 1.0000e-04\n",
            "Epoch 2/150\n",
            "421/421 [==============================] - 1047s 2s/step - loss: 0.4505 - categorical_accuracy: 0.7848 - categorical_crossentropy: 0.5980 - val_loss: 0.4320 - val_categorical_accuracy: 0.8100 - val_categorical_crossentropy: 0.4736 - lr: 1.0000e-04\n",
            "Epoch 3/150\n",
            "421/421 [==============================] - 1027s 2s/step - loss: 0.3741 - categorical_accuracy: 0.8052 - categorical_crossentropy: 0.5442 - val_loss: 0.3669 - val_categorical_accuracy: 0.7976 - val_categorical_crossentropy: 0.5157 - lr: 1.0000e-04\n",
            "Epoch 4/150\n",
            "421/421 [==============================] - 1018s 2s/step - loss: 0.3022 - categorical_accuracy: 0.8229 - categorical_crossentropy: 0.4721 - val_loss: 0.3394 - val_categorical_accuracy: 0.7044 - val_categorical_crossentropy: 0.7998 - lr: 1.0000e-04\n",
            "Epoch 5/150\n",
            "406/421 [===========================>..] - ETA: 31s - loss: 0.2767 - categorical_accuracy: 0.8290 - categorical_crossentropy: 0.4517"
          ]
        }
      ],
      "source": [
        "#@title Train Model\n",
        "\n",
        "from google.cloud import storage\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "restart_at_epoch = 0 # @param {type:\"integer\"}\n",
        "epochs = 150 # @param {type:\"integer\"}\n",
        "batch_size = 16 # @param {type:\"integer\"}\n",
        "verbose_callbacks = False # @param {type:\"boolean\"}\n",
        "overwrite_checkpoints = True # @param {type:\"boolean\"}\n",
        "verbose = 1 if verbose_callbacks else 0\n",
        "ignore_ilastik = False\n",
        "reduce_classes = False\n",
        "\n",
        "image_classes = 28\n",
        "\n",
        "# Set up GCS client\n",
        "client = storage.Client(project=gcs_project_id)\n",
        "gcs_train_directory = f\"{gcs_data_directory}/train\"\n",
        "gcs_eval_directory = f\"{gcs_data_directory}/eval\"\n",
        "\n",
        "# Function to parse TFRecord\n",
        "def parse_tfrecord_fn(example):\n",
        "    feature_description = {\n",
        "        'label': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, feature_description)\n",
        "    label = tf.io.decode_raw(example['label'], tf.uint8)\n",
        "    label = tf.reshape(label, (256, 256, 5))\n",
        "    if reduce_classes:\n",
        "        label_roads = tf.bitwise.bitwise_or(label[:, :, 1:2], label[:, :, 2:3])\n",
        "        label = tf.concat([label[:, :, :1], label_roads], axis=-1)\n",
        "    image = tf.io.decode_raw(example['image'], tf.uint8)\n",
        "    image = tf.reshape(image, (256, 256, image_classes ))\n",
        "    if ignore_ilastik:\n",
        "        image = tf.concat([image[:, :, :4], image[:, :, -5:]], axis=-1)\n",
        "    return image, label\n",
        "\n",
        "# GCS paths for training and evaluation\n",
        "gcs_train_pattern = 'gs://{}/{}/*.tfrecord'.format(gcs_bucket_name, gcs_train_directory)\n",
        "gcs_eval_pattern = 'gs://{}/{}/*.tfrecord'.format(gcs_bucket_name, gcs_eval_directory)\n",
        "\n",
        "# Get the list of file paths matching the pattern\n",
        "gcs_train_files = tf.io.gfile.glob(gcs_train_pattern)\n",
        "gcs_eval_files = tf.io.gfile.glob(gcs_eval_pattern)\n",
        "\n",
        "# Calculate steps_per_epoch\n",
        "steps_per_epoch = len(gcs_train_files) * TFRecord_batch_size // batch_size\n",
        "validation_steps = len(gcs_eval_files) * TFRecord_batch_size // batch_size\n",
        "print(f\"{steps_per_epoch} steps per epoch and {validation_steps} validation steps.\")\n",
        "\n",
        "# Create TFRecord dataset from GCS paths\n",
        "train_dataset = tf.data.TFRecordDataset(gcs_train_files)\n",
        "eval_dataset = tf.data.TFRecordDataset(gcs_eval_files)\n",
        "\n",
        "# Map the parsing function and shuffle the training dataset\n",
        "# train_dataset = train_dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(buffer_size=1000)\n",
        "train_dataset = train_dataset.map(parse_tfrecord_fn).shuffle(buffer_size=1000) # Remove AUTOTUNE to save memory?\n",
        "# Create padded batches for the training dataset and repeat indefinitely\n",
        "train_dataset = train_dataset.padded_batch(batch_size, drop_remainder=True).repeat()\n",
        "\n",
        "# Map the parsing function and shuffle the validation dataset\n",
        "# val_dataset = eval_dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(buffer_size=1000)\n",
        "val_dataset = eval_dataset.map(parse_tfrecord_fn).shuffle(buffer_size=1000) # Remove AUTOTUNE to save memory?\n",
        "# Create padded batches for the validation dataset\n",
        "val_dataset = val_dataset.padded_batch(batch_size, drop_remainder=True).repeat()\n",
        "\n",
        "# # Take a small subset of records for testing\n",
        "# train_dataset = train_dataset.take(8)\n",
        "# val_dataset = val_dataset.take(2)\n",
        "\n",
        "assert isinstance(train_dataset, tf.data.Dataset), \"train_dataset should be a tf.data.Dataset\"\n",
        "assert isinstance(val_dataset, tf.data.Dataset), \"val_dataset should be a tf.data.Dataset\"\n",
        "\n",
        "def update_filepath(model_filepath, epoch):\n",
        "    model_filepath = re.sub(r'_epoch(\\d+)\\.keras', lambda match: f'_epoch{int(match.group(1)) + epoch}.keras', model_filepath)\n",
        "    return model_filepath\n",
        "\n",
        "def convert_np_floats(obj):\n",
        "    if isinstance(obj, np.float32):\n",
        "        return float(obj)\n",
        "    return obj\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "if overwrite_checkpoints:\n",
        "    checkpoint_filepath = model_filepath\n",
        "else:\n",
        "    checkpoint_filepath = model_filepath.replace('.keras', '-{epoch:02d}-{val_categorical_crossentropy:.2f}_checkpoint.keras')\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_categorical_crossentropy',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto',\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Define the Early Stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_categorical_crossentropy',\n",
        "    patience=16,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "# Define the Learning Rate reduction callback\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_categorical_crossentropy',\n",
        "    factor=0.4,\n",
        "    patience=5,\n",
        "    min_lr=1e-9,\n",
        "    verbose=verbose\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    initial_epoch=restart_at_epoch,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    shuffle=True,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[checkpoint_callback, reduce_lr, early_stopping]\n",
        "    )\n",
        "\n",
        "if early_stopping.stopped_epoch > 0:\n",
        "    model_filepath = update_filepath(model_filepath, early_stopping.stopped_epoch)\n",
        "    print(f\"Training stopped at epoch {early_stopping.stopped_epoch} due to early stopping.\")\n",
        "else:\n",
        "    model_filepath = update_filepath(model_filepath, epochs)\n",
        "    print(\"Training completed all epochs.\")\n",
        "\n",
        "try:\n",
        "    model.save(model_filepath)\n",
        "    print(f\"Model saved successfully at: {model_filepath}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the model: {e}\")\n",
        "\n",
        "# Save the complete training history as a JSON file\n",
        "history_filepath = model_filepath.replace('.keras', '.history.json')\n",
        "try:\n",
        "    with open(history_filepath, 'w') as json_file:\n",
        "        json.dump(history.history, json_file, default=convert_np_floats)\n",
        "    print(f\"History saved successfully at: {history_filepath}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the history: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PkXg2J5WZ5Ae"
      },
      "outputs": [],
      "source": [
        "#@title Plot history\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colormaps\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "def load_most_recent_history(directory):\n",
        "    # Get all history files in the directory\n",
        "    history_files = [f for f in os.listdir(directory) if f.endswith('.history.json')]\n",
        "\n",
        "    if not history_files:\n",
        "        print(\"No history files found in the directory.\")\n",
        "        return None\n",
        "\n",
        "    # Sort history files by ascending creation date\n",
        "    sorted_history_files = sorted(history_files, key=lambda x: os.path.getctime(os.path.join(directory, x)))\n",
        "\n",
        "    # Get the most recent history file\n",
        "    most_recent_file = sorted_history_files[-1]\n",
        "\n",
        "    with open(os.path.join(directory, most_recent_file), 'r') as file:\n",
        "        history = json.load(file)\n",
        "\n",
        "    return history\n",
        "\n",
        "def plot_best_fit_curves(history):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Define the fitting function (you need to adjust this based on your data)\n",
        "    def fit_function(x, a, b, c):\n",
        "        return a * np.exp(-b * x) + c\n",
        "\n",
        "    # Extract the number of epochs\n",
        "    epochs = np.arange(1, len(history['loss']) + 1)\n",
        "\n",
        "    # Normalize each metric individually using MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    metrics = [metric for metric in history.keys() if not metric.startswith('val_') and not metric == 'loss' and not metric == 'lr']\n",
        "\n",
        "    colors = colormaps.get_cmap('Dark2')\n",
        "\n",
        "    # Normalize and handle NaN or Inf values\n",
        "    def filterNaN(metric):\n",
        "        values = np.array(history[metric])\n",
        "        mask_finite = np.isfinite(values)\n",
        "        masked_values = values[mask_finite]\n",
        "        if not masked_values.size:\n",
        "            return None\n",
        "        normalized_values = scaler.fit_transform([[v] for v in masked_values])\n",
        "        return normalized_values\n",
        "\n",
        "    for metric in metrics:\n",
        "\n",
        "        normalized_values = filterNaN(metric)\n",
        "        if normalized_values is None:\n",
        "            continue  # Skip the metric if there are no valid values\n",
        "        # Fit and plot the curve on normalized data\n",
        "        popt, _ = curve_fit(fit_function, epochs, normalized_values.flatten())\n",
        "        plt.plot(epochs, fit_function(epochs, *popt), linestyle=':', label=f'Training {metric} (best fit)', color=colors(metrics.index(metric) / len(metrics)))\n",
        "\n",
        "        val_metric = 'val_' + metric\n",
        "        if val_metric in history:\n",
        "            normalized_values = filterNaN(val_metric)\n",
        "            if normalized_values is None:\n",
        "                continue  # Skip the metric if there are no valid values\n",
        "            plt.plot(epochs, normalized_values, linestyle='--', label=f'Validation {metric}', color=colors(metrics.index(metric) / len(metrics)))\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Normalized Metric Value')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Load the most recent history file\n",
        "most_recent_history = load_most_recent_history(model_directory)\n",
        "\n",
        "if most_recent_history is not None:\n",
        "    # Plot the best-fit curves\n",
        "    plot_best_fit_curves(most_recent_history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "kdurzr5wTa5U"
      },
      "outputs": [],
      "source": [
        "#@title Load Trained Model from Last Checkpoint\n",
        "model_filename = \"\" # @param {type:\"string\"}\n",
        "\n",
        "import importlib\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import Loss, CategoricalCrossentropy, CategoricalFocalCrossentropy\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "from osgeo import gdal\n",
        "from osgeo import osr\n",
        "from tqdm.notebook import tqdm\n",
        "import contextlib\n",
        "import shutil\n",
        "\n",
        "ignore_ilastik = False\n",
        "reduce_classes = False\n",
        "\n",
        "label_strings = []\n",
        "with open(label_strings_file, 'r') as file:\n",
        "    for line in file:\n",
        "        label = line.strip()  # Remove leading/trailing whitespace, like newline characters\n",
        "        label_strings.append(label)\n",
        "\n",
        "def load_class_weights(model_directory):\n",
        "    class_weights_file = os.path.join(model_directory, 'class_weights.json')\n",
        "    if os.path.exists(class_weights_file):\n",
        "        with open(class_weights_file, 'r') as json_file:\n",
        "            class_weights = json.load(json_file)\n",
        "            class_weights = {int(key): value for key, value in class_weights.items()}  # Convert keys to integers\n",
        "\n",
        "            # Convert class_weights to a list, matching the number of classes\n",
        "            num_classes = 5\n",
        "            class_weights_list = np.array([class_weights[i] for i in range(num_classes)], dtype=np.float32)\n",
        "            print(f\"class_weights_list: {class_weights}\")\n",
        "\n",
        "            if reduce_classes:\n",
        "                adjusted_class_weights = np.zeros(2, dtype=np.float32)\n",
        "                adjusted_class_weights[0] = 1 / (1 / class_weights_list[0] + 1 / class_weights_list[3] + 1 / class_weights_list[4])\n",
        "                adjusted_class_weights[1] = 1 / (1 / class_weights_list[1] + 1 / class_weights_list[2])\n",
        "                class_weights_list = adjusted_class_weights\n",
        "                print(f\"Adjusted Class Weights: {class_weights_list}\")\n",
        "\n",
        "            return class_weights_list\n",
        "    else:\n",
        "        raise ValueError(\"Class weights not found. Cannot proceed without class weights.\")\n",
        "\n",
        "class_weights_list = load_class_weights(model_directory)\n",
        "\n",
        "def load_trained_model(model_filename=\"\", model_directory=model_directory):\n",
        "    if model_filename == \"\":\n",
        "        # If no specific model filename is provided, find the most recently saved model checkpoint\n",
        "        model_files = [f for f in os.listdir(model_directory) if f.endswith('_checkpoint.keras')]\n",
        "        if not model_files:\n",
        "            raise FileNotFoundError(\"No saved models found in the specified directory.\")\n",
        "\n",
        "        model_files.sort(key=lambda x: os.path.getmtime(os.path.join(model_directory, x)), reverse=True)\n",
        "        most_recent_model = model_files[0]\n",
        "        model_path = os.path.join(model_directory, most_recent_model)\n",
        "    else:\n",
        "        # If a model filename is provided, use that\n",
        "        model_path = os.path.join(model_directory, model_filename)\n",
        "\n",
        "    try:\n",
        "        print(f\"Loading model from: {model_path}\")\n",
        "        model = load_model(model_path, compile=False)\n",
        "        print(f\"... Loaded model from: {model_path}\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error loading the model: {str(e)}\")\n",
        "\n",
        "model = load_trained_model(model_filename)\n",
        "model.summary()\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate = initial_learning_rate),\n",
        "    loss=CategoricalFocalCrossentropy(alpha=class_weights_list),\n",
        "    metrics=['categorical_accuracy', 'categorical_crossentropy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Td7zBWzTodX9"
      },
      "outputs": [],
      "source": [
        "#@title Inference\n",
        "\n",
        "import importlib\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check if Rasterio is installed\n",
        "try:\n",
        "    import rasterio\n",
        "except ImportError:\n",
        "    !pip install rasterio\n",
        "    import rasterio\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "from osgeo import gdal\n",
        "from osgeo import osr\n",
        "from tqdm.notebook import tqdm\n",
        "import contextlib\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "include_labelled = False\n",
        "ignore_ilastik = False # @param {type:\"boolean\"}\n",
        "\n",
        "def load_trained_model(model_filename=None, model_directory=model_directory):\n",
        "    if model_filename is None:\n",
        "        # If no specific model filename is provided, find the most recently saved model\n",
        "        model_files = [f for f in os.listdir(model_directory) if f.endswith('.keras')]\n",
        "        if not model_files:\n",
        "            raise FileNotFoundError(\"No saved models found in the specified directory.\")\n",
        "\n",
        "        model_files.sort(key=lambda x: os.path.getmtime(os.path.join(model_directory, x)), reverse=True)\n",
        "        most_recent_model = model_files[0]\n",
        "        model_path = os.path.join(model_directory, most_recent_model)\n",
        "    else:\n",
        "        # If a model filename is provided, use that\n",
        "        model_path = os.path.join(model_directory, model_filename)\n",
        "\n",
        "    try:\n",
        "        model = load_model(model_path, compile=False)\n",
        "        print(f\"Loaded model from: {model_path}\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error loading the model: {str(e)}\")\n",
        "\n",
        "# Load model if necessary\n",
        "if 'model' not in locals():\n",
        "    model = load_trained_model()\n",
        "\n",
        "def post_process(predictions):\n",
        "    result_mask = np.zeros((predictions.shape[0], predictions.shape[1], 4), dtype=np.uint8)  # 4 channels for RGBa\n",
        "\n",
        "    max_class_probabilities = np.argmax(predictions, axis=-1)\n",
        "\n",
        "    for class_id, color in class_colors.items():\n",
        "        # Replace all pixels with class_id in max_class_probabilities with the corresponding color\n",
        "        result_mask[max_class_probabilities == class_id] = color\n",
        "\n",
        "    return result_mask\n",
        "\n",
        "def calculate_overlaps(map_height, map_width, tile_size, min_overlap):\n",
        "\n",
        "    horizontal_count = math.ceil((map_width - min_overlap) / (tile_size - min_overlap))\n",
        "    vertical_count = math.ceil((map_height - min_overlap) / (tile_size - min_overlap))\n",
        "\n",
        "    horizontal_overlap = (tile_size * horizontal_count - map_width) / (horizontal_count - 1)\n",
        "    vertical_overlap = (tile_size * vertical_count - map_height) / (vertical_count - 1)\n",
        "\n",
        "    return horizontal_count, horizontal_overlap, vertical_count, vertical_overlap\n",
        "\n",
        "def perform_sliding_window_inference(map_name):\n",
        "\n",
        "    augmented_map = np.load(f\"{map_augmented_s1_directory}{map_name}.augmented_s1.npy\")\n",
        "    if ignore_ilastik:\n",
        "        augmented_map = tf.concat([augmented_map[:, :, :4], augmented_map[:, :, -5:]], axis=-1)\n",
        "\n",
        "    map_height, map_width = augmented_map.shape[:2]\n",
        "\n",
        "    # Calculate the number of tiles and overlaps\n",
        "    horizontal_count, horizontal_overlap, vertical_count, vertical_overlap = calculate_overlaps(map_height, map_width, tile_size, min_overlap)\n",
        "\n",
        "    result_mask = np.zeros((map_height, map_width, 4), dtype=np.uint8)  # 4 channels for RGBA\n",
        "\n",
        "    # Create a tqdm progress bar with dynamic_ncols=True\n",
        "    patches = tqdm(total=horizontal_count * vertical_count, dynamic_ncols=True, desc=f\"Processing {map_name}\", position=0, leave=True)\n",
        "\n",
        "    for h in range(horizontal_count):\n",
        "        for v in range(vertical_count):\n",
        "\n",
        "            # Calculate the starting coordinates for the tile\n",
        "            x_start = int(h * (tile_size - horizontal_overlap))\n",
        "            y_start = int(v * (tile_size - vertical_overlap))\n",
        "\n",
        "            # Calculate the ending coordinates for the tile\n",
        "            x_end = min(x_start + tile_size, map_width)\n",
        "            y_end = min(y_start + tile_size, map_height)\n",
        "\n",
        "            # Extract the tile from the map\n",
        "            tile = augmented_map[y_start:y_end, x_start:x_end]\n",
        "\n",
        "            # Suppress the output of model.predict\n",
        "            with open(os.devnull, 'w') as fnull:\n",
        "                with contextlib.redirect_stdout(fnull):\n",
        "                    predictions = model.predict(np.expand_dims(tile, axis=0))\n",
        "\n",
        "            color_mask = post_process(predictions[0])\n",
        "\n",
        "            # Trim the color mask on all sides by half of the minimum overlap\n",
        "            trim_size = min_overlap // 2\n",
        "            trimmed_mask = color_mask[trim_size:tile_size - trim_size, trim_size:tile_size - trim_size]\n",
        "\n",
        "            # Calculate the offset for placing the trimmed color mask in the result_mask\n",
        "            offset_x = x_start + trim_size\n",
        "            offset_y = y_start + trim_size\n",
        "\n",
        "            # Place the trimmed color mask in the result_mask with the calculated offset\n",
        "            result_mask[offset_y:offset_y + tile_size - 2 * trim_size, offset_x:offset_x + tile_size - 2 * trim_size] = trimmed_mask\n",
        "\n",
        "            # Update the progress bar for each iteration\n",
        "            patches.update(1)\n",
        "\n",
        "    # Ensure the progress bar reaches 100%\n",
        "    patches.update(horizontal_count * vertical_count - patches.n)\n",
        "\n",
        "    return result_mask\n",
        "\n",
        "# Save georeferenced outputs\n",
        "def save_outputs(result_mask, map_path, map_name):\n",
        "\n",
        "    mask_output_path = f\"{map_mask_directory}{map_name}.png\"\n",
        "    overlay_output_path = f\"{map_overlay_directory}{map_name}.png\"\n",
        "    geotiff_output_path = f\"{map_geotiff_directory}{map_name}.tif\"\n",
        "\n",
        "    # Loop over paths and delete if they pre-exist\n",
        "    output_paths = [\n",
        "        mask_output_path,\n",
        "        overlay_output_path,\n",
        "        geotiff_output_path\n",
        "    ]\n",
        "    for path in output_paths:\n",
        "        if os.path.exists(path):\n",
        "            os.remove(path)\n",
        "\n",
        "    # Generate and copy georeferencing .aux.xml for png images\n",
        "    with rasterio.open(map_path) as src:\n",
        "        transform = src.transform\n",
        "        crs = src.crs\n",
        "        with rasterio.open(mask_output_path, 'w', driver='PNG', width=src.width, height=src.height, count=src.count, dtype=src.dtypes[0], crs=crs, transform=transform) as dst:\n",
        "            dst.write(src.read()) # .png will be overwritten when mask is generated\n",
        "\n",
        "        shutil.copyfile(f\"{mask_output_path}.aux.xml\", f\"{overlay_output_path}.aux.xml\")\n",
        "\n",
        "        # Save the result_mask as a PNG image\n",
        "        mask = Image.fromarray(result_mask)\n",
        "        mask.save(mask_output_path)\n",
        "\n",
        "        # Save the result_mask overlaid on the original map as a PNG image\n",
        "        jpg_image = Image.open(map_path)\n",
        "        overlay = Image.alpha_composite(jpg_image.convert(\"RGBA\"), mask)\n",
        "        overlay.save(overlay_output_path, \"PNG\")\n",
        "\n",
        "        display(overlay)\n",
        "\n",
        "        # Create a new GeoTIFF file and write the result_mask\n",
        "        with rasterio.open(geotiff_output_path, 'w', nodata=0, driver='GTiff', width=src.width, height=src.height, count=4, dtype=src.dtypes[0], crs=crs, transform=transform, compress='lzw') as dst_gt:\n",
        "            dst_gt.write(result_mask.transpose(2, 0, 1))\n",
        "\n",
        "def process_map(jpg_filename):\n",
        "      map_name = jpg_filename.replace('.jpg', '')\n",
        "      map_path = os.path.join(map_directory, jpg_filename)\n",
        "\n",
        "      label_path = f\"{labels_raster_directory}{map_name}.label.npy\"\n",
        "      if os.path.exists(label_path) and not include_labelled:\n",
        "          return {'map_name': map_name, 'processed': False}\n",
        "\n",
        "      # Perform sliding window inference\n",
        "      result_mask = perform_sliding_window_inference(map_name)\n",
        "\n",
        "      # Save outputs\n",
        "      save_outputs(result_mask, map_path, map_name)\n",
        "\n",
        "      return {'map_name': map_name, 'processed': True}\n",
        "\n",
        "inference = [process_map(jpg_filename) for jpg_filename in os.listdir(map_directory) if jpg_filename.endswith('.jpg')]\n",
        "skipped_maps = [result for result in inference if result['processed'] is False]\n",
        "if skipped_maps:\n",
        "    print(\"Skipped the following pre-labelled maps:\")\n",
        "    for skipped_map in skipped_maps:\n",
        "        print(skipped_map['map_name'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7H7pFXPQpAjE"
      },
      "outputs": [],
      "source": [
        "#@title Post-Processing\n",
        "'''\n",
        "Convert Pixel-Level Masks to Vector Representations\n",
        "Develop code to skeletonise to junction points\n",
        "Add code to post-process the pixel-level masks and convert them to vector representations\n",
        "\n",
        "Step 7: Model Evaluation\n",
        "\n",
        "Assess Model Performance\n",
        "Add code to evaluate the model using metrics and visual inspection\n",
        "\n",
        "Step 8: Model Refinement\n",
        "\n",
        "Fine-Tune the Model\n",
        "Add code to fine-tune the model based on evaluation results\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "mount_file_id": "1v3lcbY-FXW_ubk7cWMZg7kOjwtK9XCz5",
      "authorship_tag": "ABX9TyOzlJjCWvMiVXfqmcAYgMGT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}