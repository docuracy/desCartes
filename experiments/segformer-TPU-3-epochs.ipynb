{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/docuracy/desCartes/blob/main/experiments/segformer-TPU-3-epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Authenticate GCS, mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!gcloud auth application-default login\n",
        "!gcloud config set project descartes-404713\n",
        "\n",
        "!pip install wandb -qU\n",
        "!wandb login\n",
        "\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Xx4m0dgRcKNe",
        "outputId": "9e0e5065-7ead-4226-ad93-86fa4e45cb3b"
      },
      "id": "Xx4m0dgRcKNe",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=c7S0Q8eIORwwIzSoMdD4y0Ivw1oFGF&prompt=consent&token_usage=remote&access_type=offline&code_challenge=H9Bb6BXk94PvHjFx_piosBzqjmAXjTi70emQbi5yQQQ&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AQSTgQEuV8SBLV1zGzLiHqpvqOIrM6r3NTCKsgsTcRcUdjnpYkmzZrB-UfAE9Y6LDUoJ1A\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n",
            "\u001b[1;33mWARNING:\u001b[0m Your active project does not match the quota project in your local Application Default Credentials file. This might result in unexpected quota issues.\n",
            "\n",
            "To update your Application Default Credentials quota project, use the `gcloud auth application-default set-quota-project` command.\n",
            "Updated property [core/project].\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.9/336.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdocuracy\u001b[0m (\u001b[33mdocuracy-university-of-london\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.11.0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Copy Data from GCS { display-mode: \"code\" }\n",
        "import os\n",
        "import shutil\n",
        "from google.cloud import storage\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# Google Drive Path Configuration\n",
        "project_path = '/content/drive/MyDrive/desCartes'\n",
        "model_path = f'{project_path}/models'\n",
        "results_path = f'{project_path}/results'\n",
        "\n",
        "# GCS Configuration\n",
        "gcs_key_path = f'{project_path}/descartes-404713-cccf7c3921aa.json'\n",
        "gcs_project_id = 'descartes-404713'\n",
        "gcs_bucket_name = 'descartes'\n",
        "gcs_data_directory = \"training_data\"\n",
        "\n",
        "# Local directory for storing dataset\n",
        "local_data_dir = \"/content/data\"\n",
        "\n",
        "# Ensure local directories exist\n",
        "local_train_dir = f\"{local_data_dir}/train\"\n",
        "local_eval_dir = f\"{local_data_dir}/eval\"\n",
        "local_corrupt_dir = f\"{local_data_dir}/eval_corrupt\"\n",
        "os.makedirs(local_train_dir, exist_ok=True)\n",
        "os.makedirs(local_eval_dir, exist_ok=True)\n",
        "os.makedirs(local_corrupt_dir, exist_ok=True)\n",
        "\n",
        "# **Connect to GCS and list blobs**\n",
        "# Authenticate with your GCS key file\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = gcs_key_path\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Get the bucket and list blobs within the specified directory\n",
        "bucket = storage_client.bucket(gcs_bucket_name)\n",
        "blobs = list(bucket.list_blobs(prefix=gcs_data_directory)) # Get all blobs with the specified prefix\n",
        "\n",
        "# Function to check if a .pt file is loadable\n",
        "def check_loadable(file_path):\n",
        "    try:\n",
        "        data = torch.load(file_path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file {file_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Download files to respective folders\n",
        "for blob in blobs:\n",
        "    if blob.name.endswith(\".pt\"):\n",
        "        if \"/eval/\" in blob.name:\n",
        "            local_path = os.path.join(local_eval_dir, os.path.basename(blob.name))\n",
        "        else:\n",
        "            local_path = os.path.join(local_train_dir, os.path.basename(blob.name))\n",
        "\n",
        "        if not os.path.exists(local_path):\n",
        "            print(f\"Downloading {blob.name}...\")\n",
        "            blob.download_to_filename(local_path)\n",
        "\n",
        "        # Check if the file is loadable\n",
        "        if not check_loadable(local_path):\n",
        "            # If not loadable, move to the corrupt folder\n",
        "            print(f\"Moving corrupted file {local_path} to {local_corrupt_dir}\")\n",
        "            shutil.move(local_path, os.path.join(local_corrupt_dir, os.path.basename(blob.name)))\n",
        "\n",
        "print(\"✅ Train and eval files downloaded to local storage.\")\n",
        "\n",
        "# List all files in the corrupt directory\n",
        "corrupt_files = os.listdir(local_corrupt_dir)\n",
        "\n",
        "# Ensure there are corrupt files to replace\n",
        "if len(corrupt_files) == 0:\n",
        "    print(\"No corrupt files found in the eval_corrupt directory.\")\n",
        "else:\n",
        "    # Loop through the corrupt files\n",
        "    for file_name in corrupt_files:\n",
        "        corrupt_file_path = os.path.join(local_corrupt_dir, file_name)\n",
        "        duplicate_file_path = os.path.join(local_eval_dir, file_name)\n",
        "\n",
        "        # Select a random file from the train directory to duplicate\n",
        "        eval_files = os.listdir(local_eval_dir)\n",
        "        valid_file_name = random.choice(eval_files)\n",
        "        valid_file_path = os.path.join(local_eval_dir, valid_file_name)\n",
        "\n",
        "        # Copy the selected valid file to the eval folder with the name of the corrupt file\n",
        "        shutil.copy(valid_file_path, duplicate_file_path)\n",
        "        print(f\"Replaced corrupted file {file_name} with {valid_file_name}.\")\n",
        "\n",
        "print(\"✅ Corrupted files have been replaced with duplicates of valid ones.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L1oyjtPV6JnK"
      },
      "id": "L1oyjtPV6JnK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LAVtAKuebADW",
        "outputId": "2cada8e8-a5e5-4f86-8f55-3700ecebad2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0/8 using device xla:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdocuracy\u001b[0m (\u001b[33mdocuracy-university-of-london\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250324_172839-dc9c607d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation/runs/dc9c607d' target=\"_blank\">TPU-Training-b2</a></strong> to <a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation' target=\"_blank\">https://wandb.ai/docuracy-university-of-london/tpu-segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation/runs/dc9c607d' target=\"_blank\">https://wandb.ai/docuracy-university-of-london/tpu-segmentation/runs/dc9c607d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b2-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 08:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.786900</td>\n",
              "      <td>0.621730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.415600</td>\n",
              "      <td>0.336733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342700</td>\n",
              "      <td>0.347120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 08:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.786900</td>\n",
              "      <td>0.621730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.415600</td>\n",
              "      <td>0.336733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342700</td>\n",
              "      <td>0.347120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 09:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.786900</td>\n",
              "      <td>0.621730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.415600</td>\n",
              "      <td>0.336733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342700</td>\n",
              "      <td>0.347120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 08:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.786900</td>\n",
              "      <td>0.621730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.415600</td>\n",
              "      <td>0.336733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342700</td>\n",
              "      <td>0.347120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 08:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.786900</td>\n",
              "      <td>0.621730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.415600</td>\n",
              "      <td>0.336733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342700</td>\n",
              "      <td>0.347120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 08:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.786900</td>\n",
              "      <td>0.621730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.415600</td>\n",
              "      <td>0.336733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342700</td>\n",
              "      <td>0.347120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 08:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.786900</td>\n",
              "      <td>0.621730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.415600</td>\n",
              "      <td>0.336733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342700</td>\n",
              "      <td>0.347120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 08:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.786900</td>\n",
              "      <td>0.621730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.415600</td>\n",
              "      <td>0.336733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342700</td>\n",
              "      <td>0.347120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▇█</td></tr><tr><td>eval/steps_per_second</td><td>▁▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▅▅▅▅█▅▅▄▄▄▃▄▃▄▂▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▆</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▇▆▆▅▅▄▄▄▃▃▃▂▃▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.34712</td></tr><tr><td>eval/runtime</td><td>2.0303</td></tr><tr><td>eval/samples_per_second</td><td>18.717</td></tr><tr><td>eval/steps_per_second</td><td>1.478</td></tr><tr><td>total_flos</td><td>8.324092922167296e+16</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>324</td></tr><tr><td>train/grad_norm</td><td>5.99757</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3427</td></tr><tr><td>train_loss</td><td>0.68264</td></tr><tr><td>train_runtime</td><td>595.2594</td></tr><tr><td>train_samples_per_second</td><td>1.089</td></tr><tr><td>train_steps_per_second</td><td>0.544</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">TPU-Training-b2</strong> at: <a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation/runs/dc9c607d' target=\"_blank\">https://wandb.ai/docuracy-university-of-london/tpu-segmentation/runs/dc9c607d</a><br> View project at: <a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation' target=\"_blank\">https://wandb.ai/docuracy-university-of-london/tpu-segmentation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250324_172839-dc9c607d/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Train Model { display-mode: \"code\" }\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import wandb\n",
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.runtime as xr\n",
        "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor, TrainingArguments, Trainer\n",
        "\n",
        "# Read Hugging Face Hub User Access Token\n",
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')\n",
        "\n",
        "# Google Drive Path Configuration\n",
        "project_path = '/content/drive/MyDrive/desCartes'\n",
        "model_path = f'{project_path}/models'\n",
        "results_path = f'{project_path}/results'\n",
        "\n",
        "# Select Model\n",
        "model_version = 'b2'\n",
        "\n",
        "# Define class labels\n",
        "class_labels = [\"background\", \"main_road\", \"minor_road\", \"semi_enclosed_path\", \"unenclosed_path\"]\n",
        "\n",
        "# Local directory for storing dataset\n",
        "local_data_dir = \"/content/data\"\n",
        "\n",
        "# Training Configuration\n",
        "per_device_train_batch_size = 2  # Batch size for training\n",
        "per_device_eval_batch_size = per_device_train_batch_size\n",
        "gradient_accumulation_steps = 1  # Simulates a batch size of gradient_accumulation_steps * per_device_train_batch_size\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Configure label mappings\n",
        "num_classes = len(class_labels)\n",
        "id2label = {i: label for i, label in enumerate(class_labels)}\n",
        "label2id = {label: i for i, label in id2label.items()}\n",
        "\n",
        "def _mp_fn(rank):\n",
        "    # Set TPU device inside the function\n",
        "    device = xm.xla_device()\n",
        "    world_size = xr.world_size()\n",
        "    xm.master_print(f\"Process {rank}/{world_size} using device {device}\")\n",
        "\n",
        "    # Initialize WandB only for the main TPU process\n",
        "    if xm.is_master_ordinal():\n",
        "        os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
        "        wandb.init(project=\"tpu-segmentation\", name=f\"TPU-Training-{model_version}\")\n",
        "    else:\n",
        "        os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "    # Load the image processor and model inside _mp_fn\n",
        "    image_processor = SegformerImageProcessor.from_pretrained(f'nvidia/segformer-{model_version}-finetuned-ade-512-512')\n",
        "\n",
        "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "        f\"nvidia/segformer-{model_version}-finetuned-ade-512-512\",\n",
        "        num_labels=num_classes,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id,\n",
        "        ignore_mismatched_sizes=True,\n",
        "    ).to(device)\n",
        "\n",
        "    # Dataset class\n",
        "    class SegmentationDataset(Dataset):\n",
        "        def __init__(self, local_dir):\n",
        "            self.local_dir = local_dir\n",
        "            self.files = [os.path.join(local_dir, f) for f in os.listdir(local_dir) if f.endswith('.pt')]\n",
        "            self.image_processor = image_processor  # Use processor loaded inside _mp_fn\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.files)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            local_path = self.files[idx]\n",
        "\n",
        "            if not os.path.exists(local_path):\n",
        "                raise FileNotFoundError(f\"File not found: {local_path}\")\n",
        "\n",
        "            try:\n",
        "                data = torch.load(local_path)\n",
        "            except Exception as e:\n",
        "                # Log the error and skip the problematic file\n",
        "                print(f\"Error loading file {local_path}: {e}\")\n",
        "                return None\n",
        "\n",
        "            data = torch.load(local_path)\n",
        "            inputs = self.image_processor(images=data['images'], return_tensors=\"pt\")\n",
        "            pixel_values = inputs['pixel_values'].squeeze(0)\n",
        "            label = data['labels'].squeeze().long()\n",
        "            return {\"pixel_values\": pixel_values, \"labels\": label}\n",
        "\n",
        "    # Create dataset instances inside _mp_fn\n",
        "    train_dataset = SegmentationDataset(f\"{local_data_dir}/train\")\n",
        "    eval_dataset = SegmentationDataset(f\"{local_data_dir}/eval\")\n",
        "\n",
        "    # Distributed samplers (drop_last=True to prevent hanging)\n",
        "    train_sampler = DistributedSampler(\n",
        "        train_dataset, num_replicas=xm.xrt_world_size(), rank=rank, shuffle=True, drop_last=True\n",
        "    )\n",
        "    eval_sampler = DistributedSampler(\n",
        "        eval_dataset, num_replicas=xm.xrt_world_size(), rank=rank, shuffle=False, drop_last=True\n",
        "    )\n",
        "\n",
        "    # Safe TPU DataLoader setup\n",
        "    def worker_init_fn(worker_id):\n",
        "        \"\"\"Ensures each worker has a different random seed\"\"\"\n",
        "        torch.manual_seed(worker_id + rank)\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset, batch_size=per_device_train_batch_size, sampler=train_sampler,\n",
        "        num_workers=4, pin_memory=True, persistent_workers=True, worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, batch_size=per_device_eval_batch_size, sampler=eval_sampler,\n",
        "        num_workers=4, pin_memory=True, persistent_workers=True, worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    # Wrap data loaders with MpDeviceLoader for TPU support\n",
        "    train_dataloader = pl.MpDeviceLoader(train_dataloader, device)\n",
        "    eval_dataloader = pl.MpDeviceLoader(eval_dataloader, device)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
        "        dataloader_num_workers=4,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_steps=10,\n",
        "        logging_strategy=\"steps\",\n",
        "        report_to=[\"wandb\"] if xm.is_master_ordinal() else [],\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        num_train_epochs=3,\n",
        "        load_best_model_at_end=True,\n",
        "        push_to_hub=False,\n",
        "        fp16=False,\n",
        "        bf16=True,\n",
        "        run_name=f\"desCartes-{model_version}-{per_device_train_batch_size}-{gradient_accumulation_steps}-bf16\"\n",
        "    )\n",
        "\n",
        "    # Trainer: override standard dataloader methods\n",
        "    class CustomTrainer(Trainer):\n",
        "        def get_train_dataloader(self):\n",
        "            return train_dataloader  # Your manually created DataLoader\n",
        "\n",
        "        def get_eval_dataloader(self, eval_dataset=None):\n",
        "            return eval_dataloader  # Your manually created DataLoader\n",
        "\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train(resume_from_checkpoint=False)\n",
        "    xm.rendezvous(\"training_complete\")  # Ensure all TPU processes sync before exit\n",
        "\n",
        "    if xm.is_master_ordinal():\n",
        "        wandb.finish()  # Close WandB properly\n",
        "\n",
        "# Launch TPU training\n",
        "if __name__ == \"__main__\":\n",
        "    xmp.spawn(_mp_fn, args=(), start_method='fork')\n",
        "\n"
      ],
      "id": "LAVtAKuebADW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pluiD9jkbADY"
      },
      "outputs": [],
      "source": [
        "# @title Visualizing Results { display-mode: \"code\" }\n",
        "\n",
        "# Function to display images and predicted masks\n",
        "def plot_predictions(model, dataset, n_samples=3):\n",
        "    for i, (images, labels) in enumerate(dataset.take(n_samples)):\n",
        "        predictions = model(images).logits\n",
        "        predictions = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "        for j in range(min(n_samples, len(images))):\n",
        "            image = images[j].numpy()\n",
        "            label = labels[j].numpy()\n",
        "            prediction = predictions[j].numpy()\n",
        "\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "            axes[0].imshow(image)\n",
        "            axes[0].set_title('Input Image')\n",
        "            axes[1].imshow(np.argmax(label, axis=-1), cmap='viridis')\n",
        "            axes[1].set_title('True Label')\n",
        "            axes[2].imshow(prediction, cmap='viridis')\n",
        "            axes[2].set_title('Predicted Mask')\n",
        "            plt.show()\n",
        "\n",
        "# Display some predictions\n",
        "plot_predictions(model, val_dataset)\n"
      ],
      "id": "pluiD9jkbADY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fc-sohJbADY"
      },
      "outputs": [],
      "source": [
        "# @title Evaluation Metrics { display-mode: \"code\" }\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Function to calculate metrics for model evaluation\n",
        "def evaluate_model(model, dataset):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for images, labels in dataset.take(10):  # evaluate on first 10 batches\n",
        "        predictions = model(images).logits\n",
        "        preds = tf.argmax(predictions, axis=-1).numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Flatten the lists for classification_report\n",
        "    all_preds = np.concatenate(all_preds).flatten()\n",
        "    all_labels = np.concatenate(all_labels).flatten()\n",
        "\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    return report\n",
        "\n",
        "# Print evaluation metrics\n",
        "eval_report = evaluate_model(model, val_dataset)\n",
        "print(\"Evaluation Metrics:\\n\", eval_report)\n"
      ],
      "id": "1fc-sohJbADY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oZaMefIbADY"
      },
      "outputs": [],
      "source": [
        "# @title Model Saving { display-mode: \"code\" }\n",
        "# Save the trained model\n",
        "model.save_pretrained(f'{model_path}/segformer_model')\n",
        "# Save the image processor\n",
        "image_processor.save_pretrained(f'{model_path}/image_processor')\n"
      ],
      "id": "2oZaMefIbADY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0beeaRj9bADY"
      },
      "outputs": [],
      "source": [
        "# @title Visualizing Training Logs { display-mode: \"code\" }\n",
        "import os\n",
        "\n",
        "# Function to plot training logs\n",
        "def plot_logs(log_dir='./logs'):\n",
        "    log_files = [f for f in os.listdir(log_dir) if f.endswith('.json')]\n",
        "\n",
        "    if len(log_files) == 0:\n",
        "        print(\"No log files found.\")\n",
        "        return\n",
        "\n",
        "    log_file = log_files[0]\n",
        "    log_path = os.path.join(log_dir, log_file)\n",
        "    logs = []\n",
        "\n",
        "    with open(log_path, 'r') as f:\n",
        "        logs = f.readlines()\n",
        "\n",
        "    steps, losses = [], []\n",
        "    for log in logs:\n",
        "        if 'step' in log and 'loss' in log:\n",
        "            step = int(log.split('step')[1].split(',')[0].strip())\n",
        "            loss = float(log.split('loss')[1].split(',')[0].strip())\n",
        "            steps.append(step)\n",
        "            losses.append(loss)\n",
        "\n",
        "    plt.plot(steps, losses)\n",
        "    plt.xlabel('Training Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Progress')\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training logs\n",
        "plot_logs()\n"
      ],
      "id": "0beeaRj9bADY"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}