{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/docuracy/desCartes/blob/main/experiments/segformer-b4-TPU-100-epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Authenticate GCS, mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!gcloud auth application-default login\n",
        "!gcloud config set project descartes-404713\n",
        "\n",
        "!pip install wandb -qU\n",
        "!wandb login\n",
        "\n",
        "!pip install opencv-python\n",
        "\n",
        "!pip install --upgrade torch_xla torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "Xx4m0dgRcKNe",
        "outputId": "daa2f970-c120-4402-e14b-b2c234b9c326"
      },
      "id": "Xx4m0dgRcKNe",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=S18yM2UJPD4cj2r6Q1OmSf00lNtBQy&prompt=consent&token_usage=remote&access_type=offline&code_challenge=GgMbdO3lPUjOB9-tKz4-qjhfzogEgYUetfVePXucQoE&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AQSTgQEwi7de65iFAjXfHUm5rLGGT13UeVTrJQBambi4iViebnoX2XurmZ8NRuaWvw7T7A\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n",
            "\u001b[1;33mWARNING:\u001b[0m Your active project does not match the quota project in your local Application Default Credentials file. This might result in unexpected quota issues.\n",
            "\n",
            "To update your Application Default Credentials quota project, use the `gcloud auth application-default set-quota-project` command.\n",
            "Updated property [core/project].\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.9/336.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdocuracy\u001b[0m (\u001b[33mdocuracy-university-of-london\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.11.0.86\n",
            "Requirement already satisfied: torch_xla in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from torch_xla) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_xla) (2.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from torch_xla) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_xla) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_xla) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Copy Data from GCS { display-mode: \"code\" }\n",
        "import os\n",
        "import shutil\n",
        "from google.cloud import storage\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# Google Drive Path Configuration\n",
        "project_path = '/content/drive/MyDrive/desCartes'\n",
        "model_path = f'{project_path}/models'\n",
        "results_path = f'{project_path}/results'\n",
        "\n",
        "# GCS Configuration\n",
        "gcs_key_path = f'{project_path}/descartes-404713-cccf7c3921aa.json'\n",
        "gcs_project_id = 'descartes-404713'\n",
        "gcs_bucket_name = 'descartes'\n",
        "gcs_data_directory = \"training_data\"\n",
        "\n",
        "# Local directory for storing dataset\n",
        "local_data_dir = \"/content/data\"\n",
        "\n",
        "# Ensure local directories exist\n",
        "local_train_dir = f\"{local_data_dir}/train\"\n",
        "local_eval_dir = f\"{local_data_dir}/eval\"\n",
        "local_corrupt_dir = f\"{local_data_dir}/eval_corrupt\"\n",
        "os.makedirs(local_train_dir, exist_ok=True)\n",
        "os.makedirs(local_eval_dir, exist_ok=True)\n",
        "os.makedirs(local_corrupt_dir, exist_ok=True)\n",
        "\n",
        "# **Connect to GCS and list blobs**\n",
        "# Authenticate with your GCS key file\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = gcs_key_path\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Get the bucket and list blobs within the specified directory\n",
        "bucket = storage_client.bucket(gcs_bucket_name)\n",
        "blobs = list(bucket.list_blobs(prefix=gcs_data_directory)) # Get all blobs with the specified prefix\n",
        "\n",
        "# Function to check if a .pt file is loadable\n",
        "def check_loadable(file_path):\n",
        "    try:\n",
        "        data = torch.load(file_path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file {file_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Download files to respective folders\n",
        "for blob in blobs:\n",
        "    if blob.name.endswith(\".pt\"):\n",
        "        if \"/eval/\" in blob.name:\n",
        "            local_path = os.path.join(local_eval_dir, os.path.basename(blob.name))\n",
        "        else:\n",
        "            local_path = os.path.join(local_train_dir, os.path.basename(blob.name))\n",
        "\n",
        "        if not os.path.exists(local_path):\n",
        "            print(f\"Downloading {blob.name}...\")\n",
        "            blob.download_to_filename(local_path)\n",
        "\n",
        "        # Check if the file is loadable\n",
        "        if not check_loadable(local_path):\n",
        "            # If not loadable, move to the corrupt folder\n",
        "            print(f\"Moving corrupted file {local_path} to {local_corrupt_dir}\")\n",
        "            shutil.move(local_path, os.path.join(local_corrupt_dir, os.path.basename(blob.name)))\n",
        "\n",
        "print(\"✅ Train and eval files downloaded to local storage.\")\n",
        "\n",
        "# List all files in the corrupt directory\n",
        "corrupt_files = os.listdir(local_corrupt_dir)\n",
        "\n",
        "# Ensure there are corrupt files to replace\n",
        "if len(corrupt_files) == 0:\n",
        "    print(\"No corrupt files found in the eval_corrupt directory.\")\n",
        "else:\n",
        "    # Loop through the corrupt files\n",
        "    for file_name in corrupt_files:\n",
        "        corrupt_file_path = os.path.join(local_corrupt_dir, file_name)\n",
        "        duplicate_file_path = os.path.join(local_eval_dir, file_name)\n",
        "\n",
        "        # Select a random file from the train directory to duplicate\n",
        "        eval_files = os.listdir(local_eval_dir)\n",
        "        valid_file_name = random.choice(eval_files)\n",
        "        valid_file_path = os.path.join(local_eval_dir, valid_file_name)\n",
        "\n",
        "        # Copy the selected valid file to the eval folder with the name of the corrupt file\n",
        "        shutil.copy(valid_file_path, duplicate_file_path)\n",
        "        print(f\"Replaced corrupted file {file_name} with {valid_file_name}.\")\n",
        "\n",
        "print(\"✅ Corrupted files have been replaced with duplicates of valid ones.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "L1oyjtPV6JnK"
      },
      "id": "L1oyjtPV6JnK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Data from GCS { display-mode: \"code\" }\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "from google.cloud import storage\n",
        "from transformers import SegformerImageProcessor\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Google Drive Path Configuration\n",
        "project_path = '/content/drive/MyDrive/desCartes'\n",
        "\n",
        "# Google Cloud Storage (GCS) configuration\n",
        "gcs_key_path = f'{project_path}/descartes-404713-cccf7c3921aa.json'\n",
        "gcs_project_id = 'descartes-404713'\n",
        "gcs_bucket_name = 'descartes'\n",
        "gcs_data_directory = \"training_data\"\n",
        "\n",
        "# Authenticate with your GCS key file\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = gcs_key_path\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Initialize image processor (same as before)\n",
        "image_processor = SegformerImageProcessor.from_pretrained('nvidia/segformer-b2-finetuned-ade-512-512')\n",
        "\n",
        "# Function to check if a .pt file is loadable\n",
        "def check_loadable(file_data):\n",
        "    try:\n",
        "        # Attempt to load the tensor from the file data\n",
        "        data = torch.load(io.BytesIO(file_data))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return False\n",
        "\n",
        "# Load dataset from GCS into memory\n",
        "def load_data_from_gcs(bucket_name, data_directory):\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs(prefix=data_directory)  # List all blobs in the data directory\n",
        "\n",
        "    data = []  # This will hold the loaded data\n",
        "\n",
        "    for blob in blobs:\n",
        "        if blob.name.endswith(\".pt\"):\n",
        "            print(f\"Processing {blob.name}...\")\n",
        "\n",
        "            # Read the blob into memory (without saving it locally)\n",
        "            file_data = blob.download_as_bytes()\n",
        "\n",
        "            # Check if the file is loadable\n",
        "            if check_loadable(file_data):\n",
        "                try:\n",
        "                    # Load data directly into memory\n",
        "                    file_tensor = torch.load(io.BytesIO(file_data))\n",
        "                    inputs = image_processor(images=file_tensor['images'], return_tensors=\"pt\")\n",
        "                    pixel_values = inputs['pixel_values'].squeeze(0)\n",
        "                    label = file_tensor['labels'].squeeze().long()\n",
        "\n",
        "                    # Append the data to the list\n",
        "                    data.append({\"pixel_values\": pixel_values, \"labels\": label})\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {blob.name}: {e}\")\n",
        "            else:\n",
        "                print(f\"Skipping corrupt file: {blob.name}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load train and eval data from GCS\n",
        "train_data = load_data_from_gcs(gcs_bucket_name, f\"{gcs_data_directory}/train\")\n",
        "eval_data = load_data_from_gcs(gcs_bucket_name, f\"{gcs_data_directory}/eval\")\n",
        "\n",
        "# Convert the loaded data into a custom dataset\n",
        "class SegmentationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# Create datasets for training and evaluation\n",
        "train_dataset = SegmentationDataset(train_data)\n",
        "eval_dataset = SegmentationDataset(eval_data)\n",
        "\n",
        "# Now train_dataset and eval_dataset are ready to be used for training\n"
      ],
      "metadata": {
        "id": "fdJhv02p5nCA"
      },
      "id": "fdJhv02p5nCA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save SegmentationDatasets to Drive { display-mode: \"code\" }\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Save the dataset (train and eval data) to a binary file\n",
        "def save_dataset(dataset, file_path):\n",
        "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "    torch.save(dataset, file_path)\n",
        "    print(f\"Dataset saved to {file_path}\")\n",
        "\n",
        "# Define file paths for saving\n",
        "train_data_path = '/content/drive/MyDrive/desCartes/pytorch/train_data.pt'\n",
        "eval_data_path = '/content/drive/MyDrive/desCartes/pytorch/eval_data.pt'\n",
        "\n",
        "# Save the datasets\n",
        "save_dataset(train_dataset, train_data_path)\n",
        "save_dataset(eval_dataset, eval_data_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPXcAwIrAK5m",
        "outputId": "c2b4e3ea-c0d3-4dbe-ece8-85730a38bc72"
      },
      "id": "bPXcAwIrAK5m",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved to /content/drive/MyDrive/desCartes/pytorch/train_data.pt\n",
            "Dataset saved to /content/drive/MyDrive/desCartes/pytorch/eval_data.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load SegmentationDatasets from Drive { display-mode: \"code\" }\n",
        "\n",
        "import torch\n",
        "\n",
        "class SegmentationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "torch.serialization.add_safe_globals([SegmentationDataset])\n",
        "\n",
        "# Load the dataset from a binary file\n",
        "def load_dataset(file_path):\n",
        "    dataset = torch.load(file_path)\n",
        "    print(f\"Dataset loaded from {file_path}\")\n",
        "    return dataset\n",
        "\n",
        "# Define file paths for loading\n",
        "train_data_path = '/content/drive/MyDrive/desCartes/pytorch/train_data.pt'\n",
        "eval_data_path = '/content/drive/MyDrive/desCartes/pytorch/eval_data.pt'\n",
        "\n",
        "# Load the datasets from Google Drive\n",
        "eval_dataset = load_dataset(eval_data_path)\n",
        "train_dataset = load_dataset(train_data_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLmEZ9AIBh2G",
        "outputId": "0b1d4d71-6daa-4e1f-ca5f-5999d1168c4c"
      },
      "id": "kLmEZ9AIBh2G",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded from /content/drive/MyDrive/desCartes/pytorch/eval_data.pt\n",
            "Dataset loaded from /content/drive/MyDrive/desCartes/pytorch/train_data.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "f9buDciwg5eL"
      },
      "id": "f9buDciwg5eL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Read Hugging Face Hub User Access Token\n",
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "BbZw14Rpj1UT"
      },
      "id": "BbZw14Rpj1UT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LAVtAKuebADW",
        "outputId": "98d7d882-d207-4ebc-9f7e-aba677acb06d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0/8 using device xla:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/deprecation.py:172: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
            "  return func(*args, **kwargs)\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b4-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b4-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b4-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b4-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b4-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b4-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdocuracy\u001b[0m (\u001b[33mdocuracy-university-of-london\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b4-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250324_234944-2ho2w2cv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation/runs/2ho2w2cv' target=\"_blank\">TPU-Training-b4</a></strong> to <a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation' target=\"_blank\">https://wandb.ai/docuracy-university-of-london/tpu-segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/docuracy-university-of-london/tpu-segmentation/runs/2ho2w2cv' target=\"_blank\">https://wandb.ai/docuracy-university-of-london/tpu-segmentation/runs/2ho2w2cv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b4-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 768, 1, 1]) in the checkpoint and torch.Size([5, 768, 1, 1]) in the model instantiated\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:root:torch_xla.core.xla_model.xrt_world_size() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.world_size instead.\n",
            "WARNING:root:torch_xla.core.xla_model.xla_model.get_ordinal() will be removed in release 2.7. is deprecated. Use torch_xla.runtime.global_ordinal instead.\n"
          ]
        }
      ],
      "source": [
        "# @title Train Model { display-mode: \"code\" }\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import wandb\n",
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.runtime as xr\n",
        "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "from transformers import SegformerForSemanticSegmentation, SegformerImageProcessor, TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "import torch.nn as nn\n",
        "import evaluate\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "# Tidy up output [ineffective for TPUs]\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\", message=\"Some weights of SegformerForSemanticSegmentation were not initialized\", category=UserWarning)\n",
        "# warnings.filterwarnings(\"ignore\", message=\".*feature_extractor_type.*\", category=UserWarning)\n",
        "\n",
        "# Google Drive Path Configuration\n",
        "project_path = '/content/drive/MyDrive/desCartes'\n",
        "model_path = f'{project_path}/models'\n",
        "results_path = f'{project_path}/results'\n",
        "\n",
        "# Select Model\n",
        "model_version = 'b4'\n",
        "\n",
        "# Define class labels\n",
        "class_labels = [\"background\", \"main_road\", \"minor_road\", \"semi_enclosed_path\", \"unenclosed_path\"]\n",
        "\n",
        "# Local directory for storing dataset\n",
        "local_data_dir = \"/content/data\"\n",
        "\n",
        "# Training Configuration\n",
        "per_device_train_batch_size = 2  # Batch size for training\n",
        "per_device_eval_batch_size = per_device_train_batch_size\n",
        "gradient_accumulation_steps = 1  # Simulates a batch size of gradient_accumulation_steps * per_device_train_batch_size\n",
        "\n",
        "###################################################\n",
        "\n",
        "# Configure label mappings\n",
        "num_classes = len(class_labels)\n",
        "id2label = {i: label for i, label in enumerate(class_labels)}\n",
        "label2id = {label: i for i, label in id2label.items()}\n",
        "\n",
        "metric = evaluate.load(\"mean_iou\")\n",
        "def compute_metrics(eval_pred):\n",
        "    with torch.no_grad():\n",
        "        logits, labels = eval_pred\n",
        "        logits_tensor = torch.from_numpy(logits)\n",
        "\n",
        "        # Upsample logits to match labels\n",
        "        logits_tensor = nn.functional.interpolate(\n",
        "            logits_tensor,\n",
        "            size=labels.shape[-2:],  # Match height & width of labels\n",
        "            mode=\"bilinear\",\n",
        "            align_corners=False,\n",
        "        ).argmax(dim=1)  # Convert to predicted class indices\n",
        "\n",
        "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
        "\n",
        "        # Compute IoU, per-category IoU & accuracy\n",
        "        metrics = metric.compute(\n",
        "            predictions=pred_labels,\n",
        "            references=labels,\n",
        "            num_labels=num_classes,\n",
        "            ignore_index=0,  # class 0 is background/ignored\n",
        "            reduce_labels=False,\n",
        "        )\n",
        "\n",
        "        # Extract per-class IoU & accuracy\n",
        "        per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
        "        per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
        "\n",
        "        # Compute precision, recall, and F1-score (excluding background)\n",
        "        pred_flat = pred_labels.flatten()\n",
        "        labels_flat = labels.flatten()\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            labels_flat, pred_flat, average=\"weighted\", zero_division=0\n",
        "        )\n",
        "\n",
        "        # Store overall metrics\n",
        "        metrics[\"overall_accuracy\"] = metrics.pop(\"mean_accuracy\")\n",
        "        metrics[\"overall_mean_iou\"] = metrics.pop(\"mean_iou\")\n",
        "        metrics[\"precision\"] = precision\n",
        "        metrics[\"recall\"] = recall\n",
        "        metrics[\"f1_score\"] = f1\n",
        "\n",
        "        # Add per-class accuracy & IoU\n",
        "        metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
        "        metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
        "\n",
        "        return metrics\n",
        "\n",
        "def _mp_fn(rank):\n",
        "    # Set TPU device inside the function\n",
        "    device = xm.xla_device()\n",
        "    world_size = xr.world_size()\n",
        "    xm.master_print(f\"Process {rank}/{world_size} using device {device}\")\n",
        "\n",
        "    # Synchronize TPUs before starting\n",
        "    xm.rendezvous(\"start_training\")  # Ensure all TPU processes sync before proceeding\n",
        "\n",
        "    # Initialize WandB only for the main TPU process\n",
        "    if rank == 0:\n",
        "        wandb.init(project=\"tpu-segmentation\", name=f\"TPU-Training-{model_version}\")\n",
        "\n",
        "    # Load the image processor and model inside _mp_fn\n",
        "    image_processor = SegformerImageProcessor.from_pretrained(f'nvidia/segformer-{model_version}-finetuned-ade-512-512')\n",
        "\n",
        "    model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "        f\"nvidia/segformer-{model_version}-finetuned-ade-512-512\",\n",
        "        num_labels=num_classes,\n",
        "        id2label=id2label,\n",
        "        label2id=label2id,\n",
        "        ignore_mismatched_sizes=True,\n",
        "    ).to(device)\n",
        "\n",
        "    # Distributed samplers (drop_last=True to prevent hanging)\n",
        "    train_sampler = DistributedSampler(\n",
        "        train_dataset, num_replicas=world_size, rank=rank, shuffle=True, drop_last=True\n",
        "    )\n",
        "    eval_sampler = DistributedSampler(\n",
        "        eval_dataset, num_replicas=world_size, rank=rank, shuffle=False, drop_last=True\n",
        "    )\n",
        "\n",
        "    # Safe TPU DataLoader setup\n",
        "    def worker_init_fn(worker_id):\n",
        "        \"\"\"Ensures each worker has a different random seed\"\"\"\n",
        "        torch.manual_seed(worker_id + rank)\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset, batch_size=per_device_train_batch_size, sampler=train_sampler,\n",
        "        num_workers=4, pin_memory=True, persistent_workers=False, worker_init_fn=worker_init_fn\n",
        "    )\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, batch_size=per_device_eval_batch_size, sampler=eval_sampler,\n",
        "        num_workers=4, pin_memory=True, persistent_workers=False, worker_init_fn=worker_init_fn\n",
        "    )\n",
        "\n",
        "    # Wrap data loaders with MpDeviceLoader for TPU support\n",
        "    train_dataloader = pl.MpDeviceLoader(train_dataloader, device)\n",
        "    eval_dataloader = pl.MpDeviceLoader(eval_dataloader, device)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"{model_path}/checkpoints\",\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
        "        dataloader_num_workers=4,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=5,  # Keep only the last 5 checkpoints\n",
        "        logging_steps=10,\n",
        "        logging_strategy=\"steps\",\n",
        "        report_to=[\"wandb\"] if rank == 0 else [],\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        num_train_epochs=100,\n",
        "        load_best_model_at_end=True,\n",
        "        push_to_hub=False,\n",
        "        fp16=False,\n",
        "        bf16=True,\n",
        "        metric_for_best_model=\"overall_mean_iou\",  # Metric to monitor for best model\n",
        "        greater_is_better=True,  # Set to True to maximize the metric\n",
        "        run_name=f\"desCartes-{model_version}-{per_device_train_batch_size}-{gradient_accumulation_steps}-bf16\"\n",
        "    )\n",
        "\n",
        "    # Trainer: override standard dataloader methods\n",
        "    class CustomTrainer(Trainer):\n",
        "        def get_train_dataloader(self):\n",
        "            return train_dataloader\n",
        "\n",
        "        def get_eval_dataloader(self, eval_dataset=None):\n",
        "            return eval_dataloader\n",
        "\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
        "    )\n",
        "\n",
        "    trainer.train(resume_from_checkpoint=os.path.exists(f\"{model_path}/checkpoints\"))\n",
        "    xm.rendezvous(\"training_complete\")  # Ensure all TPU processes sync before exit\n",
        "\n",
        "    if rank == 0:\n",
        "        wandb.finish()  # Close WandB properly [Leave open for metrics via API]\n",
        "\n",
        "\n",
        "# Launch TPU training\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    xmp.spawn(_mp_fn, args=(), start_method='fork')\n"
      ],
      "id": "LAVtAKuebADW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pluiD9jkbADY"
      },
      "outputs": [],
      "source": [
        "# @title Visualising Results { display-mode: \"code\" }\n",
        "\n",
        "# Function to display images and predicted masks\n",
        "def plot_predictions(model, dataset, n_samples=3):\n",
        "    for i, (images, labels) in enumerate(dataset.take(n_samples)):\n",
        "        predictions = model(images).logits\n",
        "        predictions = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "        for j in range(min(n_samples, len(images))):\n",
        "            image = images[j].numpy()\n",
        "            label = labels[j].numpy()\n",
        "            prediction = predictions[j].numpy()\n",
        "\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "            axes[0].imshow(image)\n",
        "            axes[0].set_title('Input Image')\n",
        "            axes[1].imshow(np.argmax(label, axis=-1), cmap='viridis')\n",
        "            axes[1].set_title('True Label')\n",
        "            axes[2].imshow(prediction, cmap='viridis')\n",
        "            axes[2].set_title('Predicted Mask')\n",
        "            plt.show()\n",
        "\n",
        "# Display some predictions\n",
        "plot_predictions(model, val_dataset)\n"
      ],
      "id": "pluiD9jkbADY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fc-sohJbADY"
      },
      "outputs": [],
      "source": [
        "# @title Evaluation Metrics { display-mode: \"code\" }\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Function to calculate metrics for model evaluation\n",
        "def evaluate_model(model, dataset):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for images, labels in dataset.take(10):  # evaluate on first 10 batches\n",
        "        predictions = model(images).logits\n",
        "        preds = tf.argmax(predictions, axis=-1).numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Flatten the lists for classification_report\n",
        "    all_preds = np.concatenate(all_preds).flatten()\n",
        "    all_labels = np.concatenate(all_labels).flatten()\n",
        "\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    return report\n",
        "\n",
        "# Print evaluation metrics\n",
        "eval_report = evaluate_model(model, val_dataset)\n",
        "print(\"Evaluation Metrics:\\n\", eval_report)\n"
      ],
      "id": "1fc-sohJbADY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oZaMefIbADY"
      },
      "outputs": [],
      "source": [
        "# @title Model Saving { display-mode: \"code\" }\n",
        "# Save the trained model\n",
        "model.save_pretrained(f'{model_path}/segformer_model')\n",
        "# Save the image processor\n",
        "image_processor.save_pretrained(f'{model_path}/image_processor')\n"
      ],
      "id": "2oZaMefIbADY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0beeaRj9bADY"
      },
      "outputs": [],
      "source": [
        "# @title Visualising Training Logs { display-mode: \"code\" }\n",
        "import os\n",
        "\n",
        "# Function to plot training logs\n",
        "def plot_logs(log_dir='./logs'):\n",
        "    log_files = [f for f in os.listdir(log_dir) if f.endswith('.json')]\n",
        "\n",
        "    if len(log_files) == 0:\n",
        "        print(\"No log files found.\")\n",
        "        return\n",
        "\n",
        "    log_file = log_files[0]\n",
        "    log_path = os.path.join(log_dir, log_file)\n",
        "    logs = []\n",
        "\n",
        "    with open(log_path, 'r') as f:\n",
        "        logs = f.readlines()\n",
        "\n",
        "    steps, losses = [], []\n",
        "    for log in logs:\n",
        "        if 'step' in log and 'loss' in log:\n",
        "            step = int(log.split('step')[1].split(',')[0].strip())\n",
        "            loss = float(log.split('loss')[1].split(',')[0].strip())\n",
        "            steps.append(step)\n",
        "            losses.append(loss)\n",
        "\n",
        "    plt.plot(steps, losses)\n",
        "    plt.xlabel('Training Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Progress')\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training logs\n",
        "plot_logs()\n"
      ],
      "id": "0beeaRj9bADY"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}