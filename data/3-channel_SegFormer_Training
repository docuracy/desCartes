{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNrpLjWPD6x7Uz9wMDlcO/F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/docuracy/desCartes/blob/main/data/3-channel_SegFormer_Training\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgh1zXwuFOhB"
      },
      "source": [
        "# Road Vector Extraction Project Framework\n",
        "\n",
        "## 1. Initial Data Preparation\n",
        "\n",
        "### Annotate fully orthogonal rectangular areas using [QGIS](https://www.qgis.org/en/site/)\n",
        "\n",
        "* Set project CRS to EPSG:3857.\n",
        "* Configure project snapping settings.\n",
        "* Select scale for maximum magnification (e.g. 1:3390 for zoom level 16). The Magnifier control can be used to facilitate annotation.\n",
        "* Add template GeoPackage from [here](https://drive.google.com/file/d/1-61VwwLWoeOGk4lsfRx620aFJwrXkCE1/view?usp=sharing).\n",
        "* Enable editing in the `regions` layer, and using the \"Add Rectangle from Extent\" tool (Shape Digitizing Toolbar) draw the region(s) that you wish to annotate.\n",
        "* Open the labels-regions attribute table and add the XYZ URL for the basemap which is to be annotated (see [National Library of Scotland](https://maps.nls.uk/guides/georeferencing/qgis/) for examples). Indicate in the `annotated` column whether or not the region is to be annotated (otherwise it will be used for testing).\n",
        "* Fully annotate every road and path within each `annotated` region, paying particular attention to the location of junctions. Lines that meet or cross the boundary of a region should be extended a little way beyond that boundary. Use the following codes to distinguish between different types of road or path, dividing them into sections if necessary (descriptions below apply to OS 6\" maps):\n",
        "** 1: Main road (parallel thick and thin lines)\n",
        "** 2: Minor road (parallel thin lines)\n",
        "** 3: Semi-enclosed path (parallel solid and dashed lines)\n",
        "** 4: Unenclosed path (parallel dashed lines)\n",
        "\n",
        "## 2. Train [Ilastik](https://www.ilastik.org/) Pixel Classifier\n",
        "\n",
        "### Not necessary if you intend to work with 6\" Ordnance Survey maps\n",
        "\n",
        "* Use the `Generate & Augment Training Data` cell below to fetch map tiles and to create from them geotiffs covering the rectangular areas covered by your annotations.\n",
        "* Train Ilastik to classify background, roads, and other features.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pagxqe-djTb-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa688c6-29cc-4d9e-9e0b-2559edf8cf4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Authenticate GCS, mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQNXRHBq9-NY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Initialise directories and global variables\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Directory containing scripts such as 'map_from_tiles'\n",
        "scripts_directory = '/content/drive/MyDrive/Colab Notebooks/scripts'\n",
        "sys.path.append(scripts_directory)\n",
        "\n",
        "# Directories used by 'map_from_tiles'\n",
        "temp_directory = f\"{scripts_directory}/temp\"\n",
        "cache_directory = f\"{scripts_directory}/data/cache\"\n",
        "\n",
        "training_data_directory = '/content/drive/MyDrive/desCartes/training_data/'\n",
        "map_directory = f\"{training_data_directory}maps/\"\n",
        "map_classified_s1_directory = f\"{map_directory}classified_s1/\"\n",
        "map_one_inch_directory = f\"{map_directory}one_inch/\"\n",
        "map_osm_directory = f\"{map_directory}osm/\"\n",
        "map_dem_directory = f\"{map_directory}dem/\"\n",
        "map_elevation_directory = f\"{map_dem_directory}elevation/\"\n",
        "map_slope_directory = f\"{map_dem_directory}slope/\"\n",
        "map_augmented_s1_directory = f\"{map_directory}augmented_s1/\"\n",
        "map_binary_directory = f\"{map_directory}binary/\"\n",
        "map_skeleton_directory = f\"{map_directory}skeleton/\"\n",
        "map_output_directory = f\"{map_directory}output/\"\n",
        "map_mask_directory = f\"{map_output_directory}masks/\"\n",
        "map_overlay_directory = f\"{map_output_directory}overlays/\"\n",
        "map_geotiff_directory = f\"{map_output_directory}geotiffs/\"\n",
        "labels_directory = f\"{map_directory}labels/\"\n",
        "labels_raster_directory = f\"{labels_directory}raster/\"\n",
        "labels_overlay_directory = f\"{labels_directory}overlay/\"\n",
        "\n",
        "tile_directory = f\"{training_data_directory}tiles/\"\n",
        "tile_size = 512 # (px) - matches the dimensions expected by the SegFormer transformer\n",
        "min_overlap = 16 # Minimum tile overlap (px)\n",
        "\n",
        "# GeoPackage containing map annotations created in QGIS\n",
        "geopackage_path = '/content/drive/MyDrive/desCartes/templates/labels.gpkg'\n",
        "linestring_buffer = 3 # (px) Use False for no buffer\n",
        "\n",
        "maptiler_key = 'U2vLM8EbXurAd3Gq6C45'\n",
        "\n",
        "# UK Great Britain, Ordnance Survey six-inch to the mile (1:10,560), 1888-1913 https://cloud.maptiler.com/tiles/uk-osgb10k1888/\n",
        "basemap_url = 'https://api.maptiler.com/tiles/uk-osgb10k1888/{z}/{x}/{y}.jpg' + f'?key={maptiler_key}'\n",
        "\n",
        "# UK Great Britain, Ordnance Survey one-inch to the mile (1:63,360), 1888-1913 https://cloud.maptiler.com/tiles/uk-osgb63k1885/\n",
        "basemap_url_one_inch = 'https://api.maptiler.com/tiles/uk-osgb63k1885/{z}/{x}/{y}.png' + f'?key={maptiler_key}'\n",
        "\n",
        "# DEM Tiles - see https://documentation.maptiler.com/hc/en-us/articles/4405444055313-RGB-Terrain-by-MapTiler\n",
        "dem_tilesource = 'https://api.maptiler.com/tiles/terrain-rgb-v2/{z}/{x}/{y}.webp' + f'?key={maptiler_key}'\n",
        "dem_max_zoom = 14\n",
        "\n",
        "# Ilastik model used for Stage 1 pixel classification\n",
        "ilastik_project_file = \"/content/drive/MyDrive/desCartes/ilastik/preprocess.ilp\"\n",
        "ilastik_executable = './ilastik-1.4.0-Linux/run_ilastik.sh'\n",
        "\n",
        "# Directory for saving trained models\n",
        "model_directory = \"/content/drive/MyDrive/desCartes/models\"\n",
        "\n",
        "label_strings_file = os.path.join(model_directory, 'label_strings.txt')\n",
        "class_weights_file = os.path.join(model_directory, 'class_weights.json')\n",
        "num_classes = 5 # Allows for fill (zero) and road classes 1 to 4 (determined by QGIS labelling)\n",
        "\n",
        "# Google Cloud Services\n",
        "gcs_key_path = '/content/drive/MyDrive/desCartes/descartes-404713-cccf7c3921aa.json'\n",
        "gcs_project_id = 'descartes-404713'\n",
        "gcs_bucket_name = 'descartes'\n",
        "gcs_data_directory = \"training_data\"\n",
        "\n",
        "# Set the split ratios and batch size for training data\n",
        "PyTorch_batch_size = 1\n",
        "train_ratio = 0.85\n",
        "eval_ratio = 0.15\n",
        "\n",
        "initial_learning_rate = 0.0001\n",
        "\n",
        "# Inference: Color mappings for classes\n",
        "class_colors = {\n",
        "    0: (0, 0, 0, 0),  # Transparent (background)\n",
        "    1: (178,24,43,180),  # Red\n",
        "    2: (239,138,98,180),  # Orange\n",
        "    3: (84,39,136,180),  # Purple\n",
        "    4: (153,142,195,180),  # Lilac\n",
        "}\n",
        "\n",
        "# Create directories if they do not exist\n",
        "directories_to_create = [\n",
        "    temp_directory,\n",
        "    cache_directory,\n",
        "    training_data_directory,\n",
        "    map_directory,\n",
        "    map_one_inch_directory,\n",
        "    map_osm_directory,\n",
        "    map_dem_directory,\n",
        "    map_elevation_directory,\n",
        "    map_slope_directory,\n",
        "    map_classified_s1_directory,\n",
        "    map_augmented_s1_directory,\n",
        "    map_binary_directory,\n",
        "    map_skeleton_directory,\n",
        "    map_output_directory,\n",
        "    map_mask_directory,\n",
        "    map_overlay_directory,\n",
        "    map_geotiff_directory,\n",
        "    labels_directory,\n",
        "    labels_raster_directory,\n",
        "    labels_overlay_directory,\n",
        "    model_directory,\n",
        "]\n",
        "\n",
        "for directory in directories_to_create:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "def install_ilastik(): # Install only if/when needed\n",
        "    subprocess.run(['wget', 'https://files.ilastik.org/ilastik-1.4.0-Linux.tar.bz2'])\n",
        "    subprocess.run(['tar', 'xjf', 'ilastik-1.4.0-Linux.tar.bz2'])\n",
        "    subprocess.run(['rm', './ilastik-1.4.0-Linux.tar.bz2'])\n",
        "    sys.path.append('/content/ilastik-1.4.0-Linux/lib/python3.7/site-packages')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4gdF6DI1Ah6y"
      },
      "outputs": [],
      "source": [
        "#@title Load tile-fetching code\n",
        "\n",
        "'''\n",
        "map_from_tiles.py\n",
        "\n",
        "@author: Stephen Gadd, Docuracy Ltd, UK\n",
        "Adapted from https://github.com/jimutt/tiles-to-tiff\n",
        "\n",
        "This script is used to create a georeferenced map from a tile source. It uses\n",
        "the GDAL library to fetch, georeference and merge tiles of an image. The script\n",
        "takes in the tile source, output directory, map name, bounding box and\n",
        "zoom level as input. The bounding box is used to calculate the range of x and\n",
        "y coordinates of the tiles that need to be fetched. Once all the tiles are\n",
        "fetched, they are georeferenced and merged to create a single map file.\n",
        "\n",
        "'''\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import glob\n",
        "import shutil\n",
        "from osgeo import gdal\n",
        "import pyproj as proj\n",
        "import hashlib\n",
        "import base64\n",
        "from math import log, tan, radians, cos, pi, floor, degrees, atan, sinh\n",
        "\n",
        "gdal_options = {\n",
        "    'jpg': {'format': 'JPEG', 'creationOptions': ['PIXELTYPE=U8', 'JPEG_QUALITY=100', 'JPEG_SUBSAMPLE=0', 'PROGRESSIVE=NO']},\n",
        "    'webp': {'format': 'WEBP', 'creationOptions': ['RESAMPLING=NEAREST','QUALITY=100']},\n",
        "    'png': {'format': 'PNG', 'creationOptions': ['COMPRESS=DEFLATE', 'ZLEVEL=9']},\n",
        "    'tif': {'format': 'GTiff', 'creationOptions': None}\n",
        "    }\n",
        "\n",
        "def sec(x):\n",
        "    return(1/cos(x))\n",
        "\n",
        "\n",
        "def latlon_to_xyz(lat, lon, z):\n",
        "    tile_count = pow(2, z)\n",
        "    x = (lon + 180) / 360\n",
        "    y = (1 - log(tan(radians(lat)) + sec(radians(lat))) / pi) / 2\n",
        "    return(tile_count*x, tile_count*y)\n",
        "\n",
        "\n",
        "def bbox_to_xyz(lon_min, lon_max, lat_min, lat_max, z):\n",
        "    x_min, y_max = latlon_to_xyz(lat_min, lon_min, z)\n",
        "    x_max, y_min = latlon_to_xyz(lat_max, lon_max, z)\n",
        "    return(floor(x_min), floor(x_max),\n",
        "           floor(y_min), floor(y_max))\n",
        "\n",
        "\n",
        "def mercatorToLat(mercatorY):\n",
        "    return(degrees(atan(sinh(mercatorY))))\n",
        "\n",
        "\n",
        "def y_to_lat_edges(y, z):\n",
        "    tile_count = pow(2, z)\n",
        "    unit = 1 / tile_count\n",
        "    relative_y1 = y * unit\n",
        "    relative_y2 = relative_y1 + unit\n",
        "    lat1 = mercatorToLat(pi * (1 - 2 * relative_y1))\n",
        "    lat2 = mercatorToLat(pi * (1 - 2 * relative_y2))\n",
        "    return(lat1, lat2)\n",
        "\n",
        "\n",
        "def x_to_lon_edges(x, z):\n",
        "    tile_count = pow(2, z)\n",
        "    unit = 360 / tile_count\n",
        "    lon1 = -180 + x * unit\n",
        "    lon2 = lon1 + unit\n",
        "    return(lon1, lon2)\n",
        "\n",
        "\n",
        "def tile_edges(x, y, z):\n",
        "    lat1, lat2 = y_to_lat_edges(y, z)\n",
        "    lon1, lon2 = x_to_lon_edges(x, z)\n",
        "    return[lon1, lat1, lon2, lat2]\n",
        "\n",
        "\n",
        "def fetch_tile(x, y, z, tile_source, cache_dir, temp_dir, filetype):\n",
        "\n",
        "    cache_path = f'{cache_dir}/{x}_{y}_{z}.{filetype}'\n",
        "    if os.path.exists(cache_path):\n",
        "        shutil.copy(cache_path, temp_dir)\n",
        "        return cache_path\n",
        "\n",
        "    url = tile_source.replace(\n",
        "        \"{x}\", str(x)).replace(\n",
        "        \"{y}\", str(y)).replace(\n",
        "        \"{z}\", str(z)).replace(\n",
        "        \"%7Bx%7D\", str(x)).replace(\n",
        "        \"%7By%7D\", str(y)).replace(\n",
        "        \"%7Bz%7D\", str(z))\n",
        "\n",
        "    if not tile_source.startswith(\"http\"):\n",
        "        return url.replace(\"file:///\", \"\")\n",
        "\n",
        "    path = f'{temp_dir}/{x}_{y}_{z}.{filetype}'\n",
        "\n",
        "    req = urllib.request.Request(\n",
        "        url,\n",
        "        data=None,\n",
        "        headers={\n",
        "            'User-Agent': 'desCartes (+https://github.com/docuracy/desCartes)'\n",
        "        }\n",
        "    )\n",
        "    g = urllib.request.urlopen(req)\n",
        "\n",
        "    if filetype == 'webp': # Convert to png to avoid band distortion at georeferencing stage\n",
        "        webp_image = Image.open(BytesIO(g.read()))\n",
        "        png_image_path = path.replace(\".webp\", \".png\")\n",
        "        webp_image.save(png_image_path, format=\"PNG\")\n",
        "        return png_image_path\n",
        "\n",
        "    elif filetype == 'png': # Remove alpha channel to avoid distortion at mosaicing stage\n",
        "        png_image = Image.open(BytesIO(g.read()))\n",
        "        png_image.convert('RGB').save(path, format=\"PNG\")\n",
        "        return path\n",
        "\n",
        "    else:\n",
        "        with open(path, 'b+w') as f:\n",
        "            f.write(g.read())\n",
        "        return path\n",
        "\n",
        "def merge_tiles(input_pattern, output_path, extent, crs, temp_dir, filetype):\n",
        "\n",
        "    input_files = glob.glob(input_pattern)\n",
        "    if not input_files:\n",
        "        print(f\"No files found matching pattern: {input_pattern}\")\n",
        "        return\n",
        "\n",
        "    print(gdal_options[filetype])\n",
        "\n",
        "    vrt_path = os.path.join(temp_dir, \"tiles.vrt\")\n",
        "    gdal.BuildVRT(vrt_path, input_files, addAlpha=False)\n",
        "    print(f'Projecting {extent} to {crs}')\n",
        "    gdal.Translate(\n",
        "        output_path,\n",
        "        vrt_path,\n",
        "        outputSRS=crs,\n",
        "        projWin=[extent[0], extent[3], extent[2], extent[1]],\n",
        "        format=gdal_options[filetype]['format'],\n",
        "        creationOptions=gdal_options[filetype]['creationOptions'],\n",
        "        # resampleAlg='cubic'\n",
        "    )\n",
        "\n",
        "def georeference_raster_tile(x, y, z, path, crs, temp_dir, filetype, tilesize):\n",
        "    bounds = tile_edges(x, y, z)\n",
        "\n",
        "    # Create the projection transformer and transform from EPSG:4326\n",
        "    transformer = proj.Transformer.from_crs(\"EPSG:4326\", crs, always_xy=True)\n",
        "    bounds[0],bounds[1] = transformer.transform(bounds[0], bounds[1])\n",
        "    bounds[2],bounds[3] = transformer.transform(bounds[2], bounds[3])\n",
        "\n",
        "    # Save the original tile to a temporary file\n",
        "    original_tile_path = os.path.join(temp_dir, f'original_{x}_{y}_{z}.{filetype}')\n",
        "    shutil.copy(path, original_tile_path)\n",
        "\n",
        "    gdal.Translate(os.path.join(temp_dir, f'{temp_dir}/{x}_{y}_{z}.{filetype}'),\n",
        "           original_tile_path,\n",
        "           outputSRS=crs,\n",
        "           outputBounds=bounds,\n",
        "           width=tilesize['x'],\n",
        "           height=tilesize['y'],\n",
        "           format=gdal_options[filetype]['format'],\n",
        "           creationOptions=gdal_options[filetype]['creationOptions'],\n",
        "           )\n",
        "\n",
        "    os.remove(original_tile_path)\n",
        "\n",
        "def create_map(tile_source, output_dir, map_name, bounding_box, zoom, crs, temp_dir, cache_dir_root, filetype='jpg'):\n",
        "\n",
        "    filetype = tile_source.split('.')[-1].split('?')[0]\n",
        "\n",
        "    bounding_box_original = bounding_box\n",
        "\n",
        "    if not crs == 'EPSG:4326':\n",
        "\n",
        "        # Create the projection transformer to EPSG:4326\n",
        "        transformer = proj.Transformer.from_crs(crs, \"EPSG:4326\", always_xy=True)\n",
        "\n",
        "        # Extract the coordinates of the extent\n",
        "        xminOld, yminOld, xmaxOld, ymaxOld = bounding_box\n",
        "\n",
        "        # Use the transformer to convert the extent\n",
        "        xmin4326, ymin4326 = transformer.transform(xminOld, yminOld)\n",
        "        xmax4326, ymax4326 = transformer.transform(xmaxOld, ymaxOld)\n",
        "\n",
        "        bounding_box = (xmin4326, ymin4326, xmax4326, ymax4326)\n",
        "\n",
        "    # Print the extent\n",
        "    print(f\"Extent of {map_name}: {bounding_box}\")\n",
        "\n",
        "    lon_min, lat_min, lon_max, lat_max = bounding_box\n",
        "\n",
        "    # Create a cache directory name\n",
        "    hash_obj = hashlib.sha256(tile_source.encode())\n",
        "    hash_bytes = hash_obj.digest()\n",
        "    hash_b64 = base64.urlsafe_b64encode(hash_bytes).decode()\n",
        "    cache_dir = os.path.join(cache_dir_root, hash_b64)\n",
        "\n",
        "    # Script start:\n",
        "    if not os.path.exists(temp_dir):\n",
        "        os.makedirs(temp_dir)\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    x_min, x_max, y_min, y_max = bbox_to_xyz(\n",
        "        lon_min, lon_max, lat_min, lat_max, zoom)\n",
        "\n",
        "    total_tiles = (x_max - x_min + 1) * (y_max - y_min + 1)\n",
        "    counter = 0\n",
        "    tilesize = None\n",
        "    print(f\"Fetching & georeferencing {total_tiles} tiles...\")\n",
        "\n",
        "    for x in range(x_min, x_max + 1):\n",
        "        for y in range(y_min, y_max + 1):\n",
        "            counter += 1\n",
        "            try:\n",
        "                tile_path = fetch_tile(x, y, zoom, tile_source, cache_dir, temp_dir, filetype)\n",
        "                if filetype == 'webp': # (Converted by fetch_tile)\n",
        "                    filetype = 'png'\n",
        "                percent_done = counter / total_tiles * 100\n",
        "                print(f\"{percent_done:.1f}% : {x},{y} {'found in cache.' if cache_dir in tile_path else 'fetched from tileserver.'}\", end='\\r')\n",
        "                if tilesize is None:\n",
        "                    print(f'Fetching tile size of {tile_path}...')\n",
        "                    ds = gdal.Open(tile_path)\n",
        "                    tilesize = {'x': ds.RasterXSize, 'y': ds.RasterYSize}\n",
        "                    ds = None\n",
        "                    print(f'... {tilesize}')\n",
        "                georeference_raster_tile(x, y, zoom, tile_path, crs, temp_dir, filetype, tilesize)\n",
        "            except OSError:\n",
        "                print(f\"Error, failed to get {x},{y}\")\n",
        "                pass\n",
        "\n",
        "    if tilesize is None:\n",
        "        print(\"Failed to fetch any tiles for this extent.\")\n",
        "        filename = None\n",
        "\n",
        "    else:\n",
        "\n",
        "        print(\"Resolving and georeferencing of raster tiles complete.\")\n",
        "\n",
        "        print(\"Merging tiles ...\")\n",
        "        filename = os.path.join(output_dir, map_name)\n",
        "        merge_tiles(os.path.join(temp_dir, f'*.{filetype}'), filename, bounding_box_original, crs, temp_dir, filetype)\n",
        "        print(\"... complete\")\n",
        "\n",
        "        # Move any downloaded files to the cache folder\n",
        "        if not os.path.exists(cache_dir):\n",
        "            os.makedirs(cache_dir)\n",
        "        for file in os.listdir(temp_dir):\n",
        "            if file.endswith(f'.{filetype}'):\n",
        "                shutil.move(os.path.join(temp_dir, file), os.path.join(cache_dir, file))\n",
        "\n",
        "    shutil.rmtree(temp_dir)\n",
        "\n",
        "    return filename\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ERvzmSHEh_9e"
      },
      "outputs": [],
      "source": [
        "#@title Create maps from tiles\n",
        "\n",
        "#from map_from_tiles import create_map\n",
        "\n",
        "import geopandas as gpd\n",
        "import os\n",
        "\n",
        "include_DEM = True # @param {type:\"boolean\"}\n",
        "\n",
        "if include_DEM:\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    from osgeo import gdal\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Check if richdem is installed\n",
        "    try:\n",
        "        import richdem as rd\n",
        "    except ImportError:\n",
        "        !pip install richdem\n",
        "        import richdem as rd\n",
        "\n",
        "# Open the GeoPackage\n",
        "regions_gdf = gpd.read_file(geopackage_path, layer='regions')\n",
        "crs = regions_gdf.crs\n",
        "\n",
        "# Loop through each region in the GeoDataFrame\n",
        "for index, row in regions_gdf.iterrows():\n",
        "    # Extract the region name, URL, and other attributes\n",
        "    region_name = row['name']\n",
        "    geom = row['geometry']\n",
        "\n",
        "    # Get the extent (bounding box) of the geometry\n",
        "    extent = geom.bounds\n",
        "\n",
        "    map_filename = f\"{region_name}.jpg\"\n",
        "    map_path = os.path.join(map_directory, map_filename)\n",
        "    # Check if the map file already exists\n",
        "    if not os.path.exists(map_path):\n",
        "        # If it doesn't exist, create the map\n",
        "        map_path = create_map(basemap_url, map_directory, map_filename, extent, 17, crs, temp_directory, cache_directory)\n",
        "    else:\n",
        "        print(f\"The map for '{region_name}' already exists at '{map_directory}'. Skipping map creation.\")\n",
        "\n",
        "    map_one_inch_filename = f\"{region_name}.png\"\n",
        "    map_one_inch_path = os.path.join(map_one_inch_directory, map_one_inch_filename)\n",
        "    # Check if the map file already exists\n",
        "    if not os.path.exists(map_one_inch_path):\n",
        "        # If it doesn't exist, create the map\n",
        "        map_one_inch_path = create_map(basemap_url_one_inch, map_one_inch_directory, map_one_inch_filename, extent, 16, crs, temp_directory, cache_directory)\n",
        "    else:\n",
        "        print(f\"The one-inch map for '{region_name}' already exists at '{map_one_inch_directory}'. Skipping map creation.\")\n",
        "\n",
        "    if include_DEM:\n",
        "        filetype = dem_tilesource.split('.')[-1].split('?')[0]\n",
        "        if filetype == 'webp':\n",
        "            filetype = 'png'\n",
        "        map_elevation_filename = f\"{region_name}_elevation.{filetype}\"\n",
        "        map_elevation_path = os.path.join(map_elevation_directory, map_elevation_filename)\n",
        "        # Check if the map elevation file already exists\n",
        "        if not os.path.exists(map_elevation_path):\n",
        "            map_elevation_path = create_map(dem_tilesource, map_elevation_directory, map_elevation_filename, extent, dem_max_zoom, crs, temp_directory, cache_directory, filetype)\n",
        "        else:\n",
        "            print(f\"The elevation map for '{region_name}' already exists at '{map_elevation_directory}'. Skipping map elevation creation.\")\n",
        "\n",
        "        map_slope_filename = f\"{region_name}_slope.npy\"\n",
        "        map_slope_path = os.path.join(map_slope_directory, map_slope_filename)\n",
        "        # Check if the map slope file already exists\n",
        "        if not os.path.exists(map_slope_path):\n",
        "\n",
        "            # Rather convoluted due to difficulty in persuading richdem to load data any other way\n",
        "\n",
        "            # Open the original map image with GDAL\n",
        "            map_ds = gdal.Open(map_path)\n",
        "            map_width = map_ds.RasterXSize\n",
        "            map_height = map_ds.RasterYSize\n",
        "\n",
        "            # Open the elevation image with GDAL\n",
        "            elevation_ds = gdal.Open(map_elevation_path)\n",
        "\n",
        "            # Read the RGB values from the GDAL dataset\n",
        "            r_band = elevation_ds.GetRasterBand(1).ReadAsArray().astype(np.float32)\n",
        "            g_band = elevation_ds.GetRasterBand(2).ReadAsArray().astype(np.float32)\n",
        "            b_band = elevation_ds.GetRasterBand(3).ReadAsArray().astype(np.float32)\n",
        "\n",
        "            print(f\"Red: {np.min(r_band)} to {np.max(r_band)} ({np.mean(r_band)}); Green: {np.min(g_band)} to {np.max(g_band)} ({np.mean(g_band)}); Blue: {np.min(b_band)} to {np.max(b_band)} ({np.mean(b_band)}); \")\n",
        "\n",
        "            # Convert RGB values to elevation in npy array\n",
        "            elevation_map = np.array(-10000 + ((r_band * 256 * 256 + g_band * 256 + b_band) * .1)).astype(np.float32)\n",
        "            ## -10000 + ((red * 256 * 256 + green * 256 + blue) * 0.1);\n",
        "\n",
        "            # Get geotransform and projection from the JPG dataset\n",
        "            geotransform = list(elevation_ds.GetGeoTransform())\n",
        "            projection = elevation_ds.GetProjection()\n",
        "\n",
        "            # Create a GDAL in-memory dataset\n",
        "            in_mem_driver = gdal.GetDriverByName('MEM')\n",
        "            in_mem_ds = in_mem_driver.Create('', elevation_map.shape[1], elevation_map.shape[0], 1, gdal.GDT_Float32)\n",
        "\n",
        "            # Set geotransform and projection\n",
        "            in_mem_ds.SetGeoTransform(geotransform)\n",
        "            in_mem_ds.SetProjection(projection)\n",
        "\n",
        "            # Write data to the raster band\n",
        "            band = in_mem_ds.GetRasterBand(1)\n",
        "            band.WriteArray(elevation_map)\n",
        "\n",
        "            # Create a virtual file and write the in-memory dataset to it\n",
        "            virtual_file_path = '/vsimem/in_mem_dataset.tif'\n",
        "            gdal.GetDriverByName('GTiff').CreateCopy(virtual_file_path, in_mem_ds)\n",
        "\n",
        "            # Open the virtual file with richdem.LoadGDAL\n",
        "            rdarray = rd.LoadGDAL(virtual_file_path, no_data=-9999)\n",
        "\n",
        "            # Calculate slope array in degrees\n",
        "            slope_array = rd.TerrainAttribute(rdarray, attrib='slope_degrees')\n",
        "\n",
        "            # Resize slope array to map image dimensions using bicubic resampling\n",
        "            slope_image = Image.fromarray(slope_array)\n",
        "            resized_slope_image = slope_image.resize((map_width, map_height), Image.BICUBIC)\n",
        "            resized_slope_array = np.array(resized_slope_image)\n",
        "\n",
        "            # Clip slope array at 45 degrees and normalize to 0-255\n",
        "            slope_array_clipped = np.clip((resized_slope_array / 45) * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "            # Save to map_slope_path\n",
        "            np.save(map_slope_path, slope_array_clipped)\n",
        "\n",
        "            # Print summary of slope array\n",
        "            print(f\"Elevation for '{region_name}': {np.min(elevation_map)} to {np.max(elevation_map)}; Mean: {np.mean(elevation_map)}\")\n",
        "            print(f\"Slope for '{region_name}': {np.min(slope_array)} to {np.max(slope_array)}; Mean: {np.mean(slope_array)}\")\n",
        "\n",
        "            # Visualize Elevation Map\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.imshow(elevation_map, cmap='terrain', vmin=np.min(elevation_map), vmax=np.max(elevation_map))\n",
        "            plt.colorbar(label='Elevation (meters)')\n",
        "            plt.title(f'Elevation Map for {region_name}')\n",
        "            plt.show()\n",
        "\n",
        "            # Visualize Slope Array\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.imshow(slope_array_clipped, cmap='viridis', vmin=0, vmax=255)\n",
        "            plt.colorbar(label='Slope')\n",
        "            plt.title(f'Slope Map for {region_name}')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"The slope map for '{region_name}' already exists at '{map_slope_directory}'. Skipping map slope creation.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HxKEKBtFNqBR"
      },
      "outputs": [],
      "source": [
        "#@title Fetch OSM modern features\n",
        "\n",
        "# Check if OverPy is installed\n",
        "try:\n",
        "    import overpy\n",
        "except ImportError:\n",
        "    !pip install overpy\n",
        "    import overpy\n",
        "\n",
        "# Check if Rasterio is installed\n",
        "try:\n",
        "    import rasterio\n",
        "except ImportError:\n",
        "    !pip install rasterio\n",
        "    import rasterio\n",
        "\n",
        "from rasterio.transform import from_origin\n",
        "from rasterio.features import geometry_mask, rasterize\n",
        "import rasterio.transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.ops import cascaded_union\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, LineString, Polygon, mapping, box, shape\n",
        "import os\n",
        "import pyproj\n",
        "\n",
        "def convert_coords_to_4326(min_x, min_y, max_x, max_y, crs):\n",
        "    # Create a Pyproj transformer\n",
        "    transformer = pyproj.Transformer.from_crs(crs, 'EPSG:4326', always_xy=True)\n",
        "\n",
        "    # Transform the corners of the bounding box\n",
        "    min_lon, min_lat = transformer.transform(min_x, min_y)\n",
        "    max_lon, max_lat = transformer.transform(max_x, max_y)\n",
        "\n",
        "    return min_lat, min_lon, max_lat, max_lon\n",
        "\n",
        "def fetch_osm_gdf(min_lat, min_lon, max_lat, max_lon):\n",
        "    api = overpy.Overpass()\n",
        "\n",
        "    query = f\"\"\"\n",
        "    (\n",
        "      way[\"highway\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
        "      way[\"railway\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
        "      (\n",
        "        way[\"waterway\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
        "        way[\"natural\"=\"water\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
        "        way[\"landuse\"~\"^(reservoir|basin|pond|lake)$\"]({min_lat},{min_lon},{max_lat},{max_lon});\n",
        "      );\n",
        "    );\n",
        "    (._;>;);\n",
        "    out geom;\n",
        "    \"\"\"\n",
        "\n",
        "    result = api.query(query)\n",
        "\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        {\n",
        "            \"geometry\": [\n",
        "                Polygon([[float(node.lon), float(node.lat)] for node in way.nodes])\n",
        "                if way.nodes[0] == way.nodes[-1]\n",
        "                else LineString([[float(node.lon), float(node.lat)] for node in way.nodes])\n",
        "                for way in result.ways\n",
        "            ],\n",
        "            \"class\": [\n",
        "                \"motorway\" if \"highway\" in way.tags and \"motorway\" in way.tags[\"highway\"]\n",
        "                else \"rail\" if \"highway\" in way.tags and \"rail\" in way.tags[\"highway\"]\n",
        "                else \"road\" if \"highway\" in way.tags\n",
        "                else \"rail\" if \"railway\" in way.tags\n",
        "                else \"water\" if \"waterway\" in way.tags or (\n",
        "                    \"natural\" in way.tags and way.tags[\"natural\"] == \"water\"\n",
        "                ) or (\n",
        "                    \"landuse\" in way.tags\n",
        "                    and way.tags[\"landuse\"] in [\"reservoir\", \"basin\", \"pond\", \"lake\"]\n",
        "                )\n",
        "                else None\n",
        "                for way in result.ways\n",
        "            ],\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Filter out rows with class as None\n",
        "    gdf = gdf.dropna(subset=[\"class\"])\n",
        "\n",
        "    return gdf\n",
        "\n",
        "# Open the GeoPackage\n",
        "regions_gdf = gpd.read_file(geopackage_path, layer='regions')\n",
        "labels_gdf = gpd.read_file(geopackage_path, layer='labels')\n",
        "crs = regions_gdf.crs\n",
        "\n",
        "# Loop through each region in the GeoDataFrame\n",
        "for index, row in regions_gdf.iterrows():\n",
        "    # Extract the region name, URL, and other attributes\n",
        "    region_name = row['name']\n",
        "    geom = row['geometry']\n",
        "\n",
        "    osm_output_path = f\"{map_osm_directory}{region_name}_osm.npy\"\n",
        "    if os.path.exists(osm_output_path):\n",
        "        print(f\"The OSM data for '{region_name}' already exist at '{osm_output_path}'. Skipping creation.\")\n",
        "    else:\n",
        "\n",
        "        # Get the extent (bounding box) of the geometry\n",
        "        extent = geom.bounds\n",
        "        min_lat, min_lon, max_lat, max_lon = convert_coords_to_4326(*extent, crs)\n",
        "\n",
        "        osm_gdf = fetch_osm_gdf(min_lat, min_lon, max_lat, max_lon)\n",
        "        # Crop to extent\n",
        "        osm_gdf = gpd.clip(osm_gdf, box(min_lon, min_lat, max_lon, max_lat)) # Swap lat<->lon\n",
        "        osm_gdf = osm_gdf[~osm_gdf.is_empty]\n",
        "        osm_gdf = osm_gdf.explode(index_parts=True)  # Cropping can cause creation of multiparts\n",
        "\n",
        "        map_path = os.path.join(map_directory, f\"{region_name}.jpg\")\n",
        "        with rasterio.open(map_path) as map_ds:\n",
        "            transform_3857 = map_ds.transform\n",
        "            array_shape = map_ds.shape\n",
        "\n",
        "        # Function to convert coordinates to pixel values\n",
        "        def coords_to_pixel(transform_3857, lon, lat):\n",
        "            lon_3857, lat_3857 = pyproj.Transformer.from_crs('EPSG:4326', 'EPSG:3857').transform(lat, lon) # Swap lat<->lon\n",
        "            y, x = rasterio.transform.rowcol(transform_3857, lon_3857, lat_3857)\n",
        "            return int(x), int(y)\n",
        "\n",
        "        def transform_coords(geom, transform_3857):\n",
        "            if geom.geom_type == 'Polygon':\n",
        "                # Apply the transformation to the exterior ring\n",
        "                exterior_coords = [coords_to_pixel(transform_3857, *coord) for coord in geom.exterior.coords]\n",
        "\n",
        "                # Apply the transformation to each interior ring (hole)\n",
        "                interior_coords = [\n",
        "                    [coords_to_pixel(transform_3857, *coord) for coord in interior.coords]\n",
        "                    for interior in geom.interiors\n",
        "                ]\n",
        "\n",
        "                return Polygon(exterior_coords, interior_coords)\n",
        "            elif geom.geom_type == 'LineString':\n",
        "                # Apply the transformation to the LineString\n",
        "                return LineString([coords_to_pixel(transform_3857, *coord) for coord in geom.coords])\n",
        "            else:\n",
        "                # Handle other geometry types as needed\n",
        "                return None\n",
        "\n",
        "        osm_gdf['geometry'] = osm_gdf['geometry'].apply(lambda geom: transform_coords(geom, transform_3857))\n",
        "\n",
        "        # Function to buffer LineStrings and collect all geometries\n",
        "        def buffer_and_collect(row, buffer_width):\n",
        "            geometry = row['geometry']\n",
        "\n",
        "            if isinstance(geometry, LineString):\n",
        "                buffer_multiplier = 2 if row['class'] in ['motorway', 'rail'] else 1\n",
        "                geometry = geometry.buffer(buffer_width * buffer_multiplier, cap_style=2)\n",
        "\n",
        "            return geometry\n",
        "\n",
        "        # Create a dictionary to store arrays for each class\n",
        "        class_arrays = {'motorway': None, 'road': None, 'rail': None, 'water': None}\n",
        "\n",
        "        # Iterate over unique classes\n",
        "        for class_value in class_arrays.keys():\n",
        "            # Filter rows for the current class\n",
        "            class_rows = osm_gdf[osm_gdf['class'] == class_value]\n",
        "\n",
        "            # Buffer LineStrings and collect all geometries into a list\n",
        "            geometries = class_rows.apply(lambda row: buffer_and_collect(row, linestring_buffer), axis=1).tolist()\n",
        "\n",
        "            if len(geometries) > 0:\n",
        "\n",
        "                # Create an array for the current class\n",
        "                class_array = rasterio.features.rasterize(\n",
        "                    shapes=[(geom, 255) for geom in geometries],\n",
        "                    out_shape=array_shape,\n",
        "                    fill=0,\n",
        "                    all_touched=True,\n",
        "                    merge_alg=rasterio.enums.MergeAlg.replace,\n",
        "                    dtype=np.uint8\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                class_array = np.zeros(array_shape, dtype=np.uint8)\n",
        "\n",
        "            # Store the array in the dictionary with the class as the key\n",
        "            class_arrays[class_value] = class_array\n",
        "\n",
        "        stacked_array = np.stack(list(class_arrays.values()), axis=0)\n",
        "        np.save(f\"{map_osm_directory}{region_name}_osm.npy\", stacked_array)\n",
        "\n",
        "        # Iterate over each class and its corresponding array\n",
        "        for i, class_value in enumerate(class_arrays.keys()):\n",
        "            class_array = stacked_array[i, :, :]\n",
        "\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(class_array, cmap='gray', interpolation='none')\n",
        "            plt.title(f'{region_name} {class_value}')\n",
        "            plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cwKLxX6yI1Rw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj2Adb1FYVQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8b9422-c56b-440c-f3fb-1f4ad597a8c1",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 labels found: ['Blue', 'Red', 'Shading', 'Road Spot', 'Contour Spot', 'Road', 'Boundary Spot', 'Tree Broadleaf', 'Tree Conifer', 'Hatch', 'Line 5px', 'Line 3px', 'Dash 3px', 'Black Solid', 'Road Name', 'Background', 'Embankment', 'Marsh', 'Water', 'Railway'].\n",
            "Ilastik is not installed. Installing...\n",
            "... done.\n",
            "Classifying Shardlow.jpg...\n",
            "Classifying Tormarton.jpg...\n",
            "Classifying Lothersdale.jpg...\n",
            "Classifying Tolleshunt_Major.jpg...\n",
            "Classifying Snowdon.jpg...\n",
            "Classifying Walsall.jpg...\n",
            "Classifying Bristol.jpg...\n",
            "Classifying Llanfynydd.jpg...\n",
            "Classifying Bolam.jpg...\n",
            "Classifying Norton.jpg...\n",
            "Classifying Oundle.jpg...\n",
            "Classifying Stilton.jpg...\n",
            "Classifying Water_Orton.jpg...\n",
            "Classifying Bath.jpg...\n",
            "Classifying Swindon.jpg...\n",
            "Classifying Northampton.jpg...\n",
            "Classifying Papworth.jpg...\n",
            "Classifying Nottingham.jpg...\n",
            "Classifying Winchester.jpg...\n",
            "Classifying Salisbury.jpg...\n",
            "Classifying York.jpg...\n",
            "Classifying Belsay.jpg...\n",
            "Classifying Ripon.jpg...\n"
          ]
        }
      ],
      "source": [
        "#@title Ilastik: classify pixels (Stage 1)\n",
        "\n",
        "import os\n",
        "import h5py\n",
        "# import numpy as np\n",
        "# import shutil\n",
        "# import importlib\n",
        "\n",
        "reprocess_maps = True # @param {type:\"boolean\"}\n",
        "dataset_name = \"probabilities\" # User's choice\n",
        "export_source = \"Probabilities\" # Could alternatively be \"Simple Segmentation\"\n",
        "export_dtype = \"float32\" # Should be \"float32\" for probablilities (\"uint8\" does not cause normalisation to 0-255)\n",
        "output_format = \"numpy\" # Could be \"hdf5\"\n",
        "\n",
        "with h5py.File(ilastik_project_file, 'r') as f:\n",
        "    labels = f['PixelClassification']['LabelNames'][:]\n",
        "    label_strings = [label.decode('utf-8') for label in labels]\n",
        "\n",
        "    print(f\"{len(label_strings)} labels found: {label_strings}.\")\n",
        "\n",
        "    # Save label_strings to a file in the model_directory\n",
        "    with open(label_strings_file, 'w') as file:\n",
        "        for label in label_strings:\n",
        "            file.write(label + '\\n')\n",
        "\n",
        "def preprocess_map(jpg_filename):\n",
        "    jpg_path = os.path.join(map_directory, jpg_filename)\n",
        "    jpg_georeference = os.path.join(map_directory, jpg_filename.replace('.jpg', '.jpg.aux.xml'))\n",
        "    classified_s1_filename = jpg_filename.replace('.jpg','.classified_s1.npy')\n",
        "    classified_s1_path = os.path.join(map_classified_s1_directory, classified_s1_filename)\n",
        "\n",
        "    # Check if the corresponding .npy file exists\n",
        "    if reprocess_maps or not os.path.exists(classified_s1_path):\n",
        "\n",
        "        # Check if Ilastik is already installed\n",
        "        if not os.path.exists(ilastik_executable):\n",
        "            print(\"Ilastik is not installed. Installing...\")\n",
        "            install_ilastik()\n",
        "            print(\"... done.\")\n",
        "\n",
        "        # Run ilastik for the current .jpg file\n",
        "        print(f\"Classifying {jpg_filename}...\")\n",
        "        command = f\"{ilastik_executable} --headless \" \\\n",
        "                  f\"--project='{ilastik_project_file}' \" \\\n",
        "                  f\"--output_format='{output_format}' \" \\\n",
        "                  f\"--output_filename_format='{classified_s1_path}' \" \\\n",
        "                  f\"--output_internal_path='/{dataset_name}' \" \\\n",
        "                  f\"--export_source='{export_source}' \" \\\n",
        "                  f\"--export_dtype='{export_dtype}' \" \\\n",
        "                  f\"'{jpg_path}'\"\n",
        "        os.system(command)\n",
        "\n",
        "# Iterate through the .jpg files in the directory and preprocess each map\n",
        "jpg_filenames = [preprocess_map(jpg_filename) for jpg_filename in os.listdir(map_directory) if jpg_filename.endswith('.jpg')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T3ZcsAKuI6hK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NwGo3YE_UjV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Generate SegFormer Inputs from Ilastik Probabilities\n",
        "\n",
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "selected_labels = ['Line 5px', 'Line 3px', 'Black Solid'] # These are the classes most commonly used to represent roads\n",
        "\n",
        "with h5py.File(ilastik_project_file, 'r') as f:\n",
        "    labels = f['PixelClassification']['LabelNames'][:]\n",
        "    label_strings = [label.decode('utf-8') for label in labels]\n",
        "\n",
        "    print(f\"{len(label_strings)} labels found: {label_strings}.\")\n",
        "\n",
        "    # Save label_strings to a file in the model_directory\n",
        "    with open(label_strings_file, 'w') as file:\n",
        "        for label in label_strings:\n",
        "            file.write(label + '\\n')\n",
        "\n",
        "def preprocess_map(jpg_filename):\n",
        "    jpg_path = os.path.join(map_directory, jpg_filename)\n",
        "    classified_s1_filename = jpg_filename.replace('.jpg', '.classified_s1.npy')\n",
        "    classified_s1_path = os.path.join(map_classified_s1_directory, classified_s1_filename)\n",
        "    segformer_input_filename = jpg_filename.replace('.jpg', '.segformer_input.npy')\n",
        "    segformer_input_path = os.path.join(map_augmented_s1_directory, segformer_input_filename)\n",
        "\n",
        "    print(f\"Generating {segformer_input_filename}...\")\n",
        "\n",
        "    if os.path.exists(classified_s1_path):\n",
        "        # Load Ilastik probabilities\n",
        "        data = np.load(classified_s1_path)\n",
        "\n",
        "        # Get the indices for the three chosen classes\n",
        "        selected_indices = [label_strings.index(label) for label in selected_labels]\n",
        "\n",
        "        # Extract the corresponding probability maps\n",
        "        segformer_input = data[..., selected_indices]\n",
        "\n",
        "        # Save as NumPy file\n",
        "        np.save(segformer_input_path, segformer_input)\n",
        "        print(f\"Saved SegFormer input: {segformer_input.shape}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"{classified_s1_path} does not exist.\")\n",
        "\n",
        "    return jpg_filename\n",
        "\n",
        "# Iterate through the .jpg files in the directory and preprocess each map\n",
        "jpg_filenames = [preprocess_map(jpg_filename) for jpg_filename in os.listdir(map_directory) if jpg_filename.endswith('.jpg')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UoxjoZ2_I-Jq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvbuJ438NKZ3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Generate Training Data\n",
        "\n",
        "import importlib\n",
        "\n",
        "# Check if Rasterio is installed\n",
        "try:\n",
        "    import rasterio\n",
        "except ImportError:\n",
        "    !pip install rasterio\n",
        "    import rasterio\n",
        "\n",
        "from osgeo import gdal, ogr, osr\n",
        "from shapely.geometry import mapping, box, shape, LineString, MultiLineString, Polygon, MultiPolygon, LinearRing\n",
        "from shapely.errors import TopologicalError\n",
        "\n",
        "import geopandas as gpd\n",
        "from affine import Affine\n",
        "import rasterio.features\n",
        "import rasterio.enums\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import json\n",
        "import sys\n",
        "from skimage.transform import rotate\n",
        "from numpy import fliplr\n",
        "import shutil\n",
        "import requests\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "from matplotlib.colors import ListedColormap\n",
        "from io import BytesIO\n",
        "from skimage.morphology import skeletonize\n",
        "from scipy.ndimage import binary_dilation\n",
        "\n",
        "def plot_raster_with_classes(image, title=\"Labels\"):\n",
        "    # Get unique classes from the image\n",
        "    unique_classes = np.unique(image)\n",
        "\n",
        "    # Create a colormap for each class\n",
        "    cmap = plt.cm.get_cmap('viridis', len(unique_classes))\n",
        "\n",
        "    # Plot the image with different colors for each class\n",
        "    plt.imshow(image, cmap=cmap, interpolation='none')\n",
        "    plt.title(title)\n",
        "    plt.colorbar(ticks=unique_classes)\n",
        "    plt.show()\n",
        "\n",
        "def calculate_overlaps(map, tile_size, min_overlap):\n",
        "    map_width, map_height = map.RasterXSize, map.RasterYSize\n",
        "\n",
        "    horizontal_count = math.ceil((map_width - min_overlap) / (tile_size - min_overlap))\n",
        "    vertical_count = math.ceil((map_height - min_overlap) / (tile_size - min_overlap))\n",
        "\n",
        "    horizontal_overlap = (tile_size * horizontal_count - map_width) / (horizontal_count - 1)\n",
        "    vertical_overlap = (tile_size * vertical_count - map_height) / (vertical_count - 1)\n",
        "\n",
        "    return horizontal_count, horizontal_overlap, vertical_count, vertical_overlap\n",
        "\n",
        "def transform_coordinates_to_image(geometry, transform):\n",
        "    if type(geometry) in (LineString, MultiLineString):\n",
        "        return transform_line_coordinates(geometry, transform)\n",
        "    elif type(geometry) in (Polygon, MultiPolygon):\n",
        "        return transform_polygon_coordinates(geometry, transform)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported geometry type\")\n",
        "\n",
        "def transform_line_coordinates(line, transform):\n",
        "    transformed_coords = [\n",
        "        (\n",
        "            round((coord[0] - transform[0]) / transform[1]),\n",
        "            round((coord[1] - transform[3]) / transform[5])\n",
        "        )\n",
        "        for coord in line.coords\n",
        "    ]\n",
        "    return LineString(transformed_coords)\n",
        "\n",
        "def transform_polygon_coordinates(polygon, transform):\n",
        "    try:\n",
        "        exterior = polygon.exterior\n",
        "        transformed_exterior = transform_line_coordinates(exterior, transform)\n",
        "\n",
        "        interiors = []\n",
        "        for interior in polygon.interiors:\n",
        "            transformed_interior = transform_line_coordinates(interior, transform)\n",
        "            # Reverse the order of coordinates in the interior ring\n",
        "            transformed_interior = LinearRing(transformed_interior.coords[::-1])\n",
        "            interiors.append(transformed_interior)\n",
        "\n",
        "        return Polygon(transformed_exterior, interiors)\n",
        "\n",
        "    except TopologicalError:\n",
        "        # Retry with an alternative approach\n",
        "        try:\n",
        "            exterior = polygon.exterior\n",
        "            transformed_exterior = transform_line_coordinates(exterior, transform)\n",
        "\n",
        "            interiors = []\n",
        "            for interior in polygon.interiors:\n",
        "                transformed_interior = transform_line_coordinates(interior, transform)\n",
        "                interiors.append(transformed_interior)\n",
        "\n",
        "            return Polygon(transformed_exterior, interiors)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Error during polygon transformation:\", e)\n",
        "            return None  # Handle the error as needed\n",
        "\n",
        "\n",
        "def split_map(map_path, extent, tile_directory, tile_size, min_overlap, region_name, annotated, add_buffer, include_nolabels=True):\n",
        "\n",
        "    buffer_widths = { # Default pixels drawn on both sides of lines\n",
        "        1: 4,\n",
        "        2: 4,\n",
        "        3: 2,\n",
        "        4: 2,\n",
        "    }\n",
        "    padding_to_buffer = .8\n",
        "\n",
        "    map = gdal.Open(map_path)\n",
        "    map_width, map_height = map.RasterXSize, map.RasterYSize\n",
        "    horizontal_count, horizontal_overlap, vertical_count, vertical_overlap = calculate_overlaps(map, tile_size, min_overlap)\n",
        "\n",
        "    print(f\"map_width: {map_width}, map_height: {map_height}, horizontal_overlap: {horizontal_overlap}, vertical_overlap: {vertical_overlap}\")\n",
        "\n",
        "    def truecrop(gdf, extent, type):\n",
        "\n",
        "        cropped_geometries = []\n",
        "\n",
        "        for index, row in gdf.iterrows():\n",
        "            geom = row['geometry']\n",
        "            if geom.is_empty:\n",
        "                continue\n",
        "\n",
        "            # Use the extent_geometry to crop each part of the geometry\n",
        "            cropped_part = gpd.clip(gpd.GeoDataFrame(geometry=[geom]), box(*extent))\n",
        "            cropped_part = cropped_part[~cropped_part.is_empty]\n",
        "\n",
        "            if not cropped_part.empty:\n",
        "                row['geometry'] = cropped_part.iloc[0]['geometry']  # Update the 'geometry' column\n",
        "                cropped_geometries.append(row)\n",
        "\n",
        "        # Create a new GeoDataFrame with the modified rows\n",
        "        if not cropped_geometries:\n",
        "            return None\n",
        "        new_gdf = gpd.GeoDataFrame(cropped_geometries, geometry='geometry')\n",
        "\n",
        "        return new_gdf\n",
        "\n",
        "    if annotated is True:\n",
        "\n",
        "        label_raster_filepath = f\"{labels_raster_directory}{region_name}.label.npy\"\n",
        "        print(f'Labelling {region_name}.')\n",
        "        # Open the GeoPackage\n",
        "        wideroads_gdf = truecrop( gpd.read_file(geopackage_path, layer='wideroads'), extent, type='polygon' )\n",
        "        labels_gdf = truecrop( gpd.read_file(geopackage_path, layer='labels'), extent, type='linestring' )\n",
        "\n",
        "        transform = map.GetGeoTransform()  # Get the geotransformation matrix\n",
        "\n",
        "        # Collect shapes\n",
        "        shapes = []\n",
        "\n",
        "        if wideroads_gdf is not None:\n",
        "            for index, row in wideroads_gdf.iterrows():\n",
        "                # Skip if the class is greater than num_classes\n",
        "                if row['class'] >= num_classes:\n",
        "                    continue\n",
        "                row['geometry'] = transform_coordinates_to_image(row['geometry'], transform)\n",
        "                shapes.append((row['geometry'], row['class']))\n",
        "\n",
        "        if labels_gdf is not None:\n",
        "            for index, row in labels_gdf.iterrows():\n",
        "                # Skip if the class is greater than num_classes\n",
        "                if row['type'] >= num_classes:\n",
        "                    continue\n",
        "                row['geometry'] = transform_coordinates_to_image(row['geometry'], transform)\n",
        "                if add_buffer is True:\n",
        "                    buffer = math.floor(row['padding'] * padding_to_buffer) if row['padding'].is_integer() else buffer_widths.get(row['type'], 0)\n",
        "                    row['geometry'] = row['geometry'].buffer(buffer)\n",
        "                elif isinstance(add_buffer, int) and add_buffer > 0:\n",
        "                    row['geometry'] = row['geometry'].buffer(add_buffer)\n",
        "                shapes.append((row['geometry'], row['type']))\n",
        "\n",
        "        # Sort the shapes in descending order of 'type'/'class' value (primary roads drawn last)\n",
        "        shapes.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Use rasterio.features.rasterize with the sorted shapes list\n",
        "        label_image = rasterio.features.rasterize(\n",
        "            shapes=shapes,\n",
        "            out_shape=(map_height, map_width),\n",
        "            fill=0,\n",
        "            all_touched=True,\n",
        "            merge_alg=rasterio.enums.MergeAlg.replace,\n",
        "            dtype=np.uint8\n",
        "        )\n",
        "\n",
        "        def save_map_with_labels(rgb_image, label_image, extent, region_name):\n",
        "\n",
        "            # Create a PIL Image from the rgb_image\n",
        "            img = Image.fromarray(rgb_image)\n",
        "\n",
        "            # Create an ImageDraw object\n",
        "            draw = ImageDraw.Draw(img)\n",
        "\n",
        "            # Draw the overlay using the specified colors for each class\n",
        "            for class_label, color in class_colors.items():\n",
        "                if class_label == 0:\n",
        "                    continue  # Skip the background class\n",
        "                overlay_pixels = (label_image == class_label)\n",
        "                for i in range(img.width):\n",
        "                    for j in range(img.height):\n",
        "                        if overlay_pixels[j, i]:\n",
        "                            draw.point((i, j), fill=color)\n",
        "\n",
        "            # Save the resulting image\n",
        "            overlay_path = f'{labels_overlay_directory}{region_name}.png'\n",
        "            img.save(overlay_path, 'PNG')\n",
        "\n",
        "        # Read the RGB image data\n",
        "        rgb_image_data = map.ReadAsArray().transpose(1, 2, 0)\n",
        "\n",
        "        # Plot the map with labels\n",
        "        save_map_with_labels(rgb_image_data, label_image, extent, region_name)\n",
        "\n",
        "        np.save(label_raster_filepath, label_image)\n",
        "\n",
        "        # Load preprocessed map image\n",
        "        preprocessed = np.load(f\"{map_augmented_s1_directory}{region_name}.segformer_input.npy\")\n",
        "\n",
        "        # Initialize the tqdm progress bar\n",
        "        total_iterations = horizontal_count * vertical_count\n",
        "        progress_bar = tqdm(total=total_iterations, desc=f\"Processing {region_name}\")\n",
        "\n",
        "        for x_loop in range(0, horizontal_count):\n",
        "            for y_loop in range(0, vertical_count):\n",
        "\n",
        "                x = round(x_loop * (tile_size - horizontal_overlap))\n",
        "                y = round(y_loop * (tile_size - vertical_overlap))\n",
        "\n",
        "                # Create a road image for the current tile\n",
        "                label_tile = label_image[y:y + tile_size, x:x + tile_size]\n",
        "\n",
        "                if include_nolabels or np.any(label_tile[..., 0] == 0): # Skip tiles without road labelling\n",
        "\n",
        "                    label_tile_path = f\"{tile_directory}{region_name}_{x}_{y}.label.npy\"\n",
        "                    np.save(label_tile_path, label_tile)\n",
        "                    # Create a preprocessed map image for the current tile\n",
        "                    preprocessed_tile = preprocessed[y:y + tile_size, x:x + tile_size]\n",
        "                    preprocessed_tile_path = f\"{tile_directory}{region_name}_{x}_{y}.segformer_input.npy\"\n",
        "                    np.save(preprocessed_tile_path, preprocessed_tile)\n",
        "\n",
        "                progress_bar.update(1)\n",
        "\n",
        "        # Ensure the progress bar reaches 100%\n",
        "        progress_bar.update(total_iterations - progress_bar.n)\n",
        "        progress_bar.close()\n",
        "\n",
        "# Clear any pre-existing tiles\n",
        "if os.path.exists(tile_directory):\n",
        "    shutil.rmtree(tile_directory)\n",
        "os.makedirs(tile_directory)\n",
        "\n",
        "# Open the GeoPackage\n",
        "regions_gdf = gpd.read_file(geopackage_path, layer='regions')\n",
        "\n",
        "# Loop through each region in the GeoDataFrame\n",
        "for index, row in regions_gdf.iterrows():\n",
        "    # Extract the region name, URL, and other attributes\n",
        "    region_name = row['name']\n",
        "    annotated = row['annotated']\n",
        "    geom = row['geometry']\n",
        "\n",
        "    # Get the extent (bounding box) of the geometry\n",
        "    extent = geom.bounds\n",
        "\n",
        "    map_filename = f\"{region_name}.jpg\"\n",
        "    map_path = os.path.join(map_directory, map_filename)\n",
        "\n",
        "    # Carve map and labels into square chips\n",
        "    min_overlap = 16 # Minimum tile overlap (px)\n",
        "    split_map(map_path, extent, tile_directory, tile_size, min_overlap, region_name, annotated, add_buffer=True, include_nolabels=True)\n",
        "\n",
        "    # if index==0:\n",
        "    #     sys.exit()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create PyTorch datasets and copy to Google Drive\n",
        "\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "augment_training_data = True  # @param {type:\"boolean\"}\n",
        "eval_ratio = 0.2  # Set evaluation split ratio\n",
        "drive_mount_path = \"/content/drive/MyDrive/desCartes/pytorch\"\n",
        "\n",
        "class SegmentationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "def augment(tensor):\n",
        "    if not augment_training_data:\n",
        "        return [tensor]\n",
        "    rotations = [torch.rot90(tensor, k, dims=(-2, -1)) for k in range(4)]\n",
        "    flipped = [rot.flip(-1) for rot in rotations]  # Flip each rotated version\n",
        "    return rotations + flipped  # 8 variations\n",
        "\n",
        "# Function to create PyTorch dataset and save as a single file\n",
        "def create_pytorch_dataset(files, output_filename):\n",
        "    data = []\n",
        "\n",
        "    for file in tqdm(files, desc=f\"Processing {output_filename}\"):\n",
        "        label_path = os.path.join(tile_directory, file)\n",
        "        image_path = label_path.replace(\".label.npy\", \".segformer_input.npy\")\n",
        "\n",
        "        # Load and augment the image and label\n",
        "        augmented_images = augment(torch.tensor(np.transpose(np.load(image_path), (2, 0, 1)).astype(np.float32)))\n",
        "        augmented_labels = augment(torch.tensor(np.load(label_path), dtype=torch.long))\n",
        "\n",
        "        # Create dictionary of image-label pairs for each augmented variation\n",
        "        for img, lbl in zip(augmented_images, augmented_labels):\n",
        "            data.append({'pixel_values': img, 'labels': lbl})\n",
        "\n",
        "    # Wrap data in SegmentationDataset class\n",
        "    dataset = SegmentationDataset(data)\n",
        "\n",
        "    save_path = os.path.join(drive_mount_path, output_filename)\n",
        "    torch.save(dataset, save_path)\n",
        "    print(f\"Saved dataset to {save_path}\")\n",
        "\n",
        "# Split dataset\n",
        "label_files = [f for f in os.listdir(tile_directory) if f.endswith('.label.npy')]\n",
        "random.shuffle(label_files)\n",
        "trainsplit = int(len(label_files) * (1 - eval_ratio))\n",
        "train_files, eval_files = label_files[:trainsplit], label_files[trainsplit:]\n",
        "\n",
        "# Create and save datasets\n",
        "create_pytorch_dataset(train_files, \"train_dataset.pt\")\n",
        "create_pytorch_dataset(eval_files, \"eval_dataset.pt\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gnuj38hVz--s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Examine Sample Data\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Get all .label.npy files\n",
        "label_files = [f for f in os.listdir(tile_directory) if f.endswith('.label.npy')]\n",
        "\n",
        "# Select a random sample of 60 images\n",
        "sample_files = random.sample(label_files, min(60, len(label_files)))\n",
        "\n",
        "# Define a custom colormap for labels\n",
        "class_colors = [\n",
        "    (0, 0, 0),      # 0: Black (background)\n",
        "    (1, 0, 0),      # 1: Red\n",
        "    (0, 1, 0),      # 2: Green\n",
        "    (0, 0, 1),      # 3: Blue\n",
        "    (1, 1, 0)       # 4: Yellow\n",
        "]\n",
        "cmap = ListedColormap(class_colors)\n",
        "\n",
        "# Set up a grid for displaying image-label pairs\n",
        "num_cols = 2  # Image and label side by side\n",
        "num_rows = len(sample_files)  # One row per pair\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(6, 3 * num_rows))  # Smaller figure size\n",
        "\n",
        "# Display each image-label pair\n",
        "for i, file in enumerate(sample_files):\n",
        "    label_path = os.path.join(tile_directory, file)\n",
        "    image_path = label_path.replace(\".label.npy\", \".segformer_input.npy\")\n",
        "    title = file.replace(\".label.npy\", \"\")\n",
        "\n",
        "    # Load image and label\n",
        "    img = np.load(image_path)\n",
        "    label = np.load(label_path)\n",
        "\n",
        "    # Ensure images are in correct shape (CHW -> HWC if necessary)\n",
        "    img = np.transpose(img, (1, 2, 0)) if img.shape[0] == 3 else img\n",
        "\n",
        "    # Scale down both image and label to 256x256\n",
        "    img_resized = resize(img, (256, 256), anti_aliasing=True)\n",
        "    label_resized = resize(label, (256, 256), anti_aliasing=False, order=0, preserve_range=True).astype(np.uint8)\n",
        "\n",
        "    # Show input image\n",
        "    axes[i, 0].imshow(img_resized)\n",
        "    axes[i, 0].set_title(f\"{title}\")\n",
        "    axes[i, 0].axis(\"off\")\n",
        "\n",
        "    # Show label with custom colormap\n",
        "    im = axes[i, 1].imshow(label_resized, cmap=cmap, vmin=0, vmax=4)\n",
        "    axes[i, 1].set_title(f\"{title}\")\n",
        "    axes[i, 1].axis(\"off\")\n",
        "\n",
        "# Adjust layout and display\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0FR-4t_mURau"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}